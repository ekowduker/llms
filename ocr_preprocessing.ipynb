{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a9c6d0",
   "metadata": {},
   "source": [
    "Here I try the following OCR packages: tesseract; docTR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375b79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f541331",
   "metadata": {},
   "source": [
    "#### Set up the PaLM API to help with code documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99155b05",
   "metadata": {},
   "source": [
    "Set the MakerSuite API key with the provided helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded476fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from utils import get_api_key\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options as client_options_lib\n",
    "\n",
    "palm.configure(\n",
    "    api_key=os.getenv('PALM_API_KEY'),\n",
    "    transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40454587",
   "metadata": {},
   "source": [
    "Pick the model that generates text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model_bison = models[0]\n",
    "model_bison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889e875",
   "metadata": {},
   "source": [
    "Helper function to call the PaLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96690a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text(prompt, \n",
    "                  model=model_bison, \n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb11baf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Run the OCR functions with Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48110d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Technical Documentation**\n",
    "\n",
    "This code uses the Python libraries `cv2` and `pytesseract` to read and extract text from an image. The image is first read into memory using the `cv2.imread()` function. The `pytesseract.image_to_string()` function is then used to convert the image to text. The `custom_config` parameter is used to specify custom options for the `pytesseract` library. In this case, the `-oem 3` option is used to enable the LSTM-based OCR engine, and the `-psm 6` option is used to specify that the image should be scanned for text using a single pass.\n",
    "\n",
    "**Output**\n",
    "\n",
    "The output of the code is the text that was extracted from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385f89d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.390] global loadsave.cpp:248 findDecoder imread_('test_graham_g.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported image object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m custom_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--oem 3 --psm 6\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the image to text\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Print the text\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[0;32m~/ml/my_python310_env/lib/python3.10/site-packages/pytesseract/pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml/my_python310_env/lib/python3.10/site-packages/pytesseract/pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[1;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[0;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/ml/my_python310_env/lib/python3.10/site-packages/pytesseract/pytesseract.py:277\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_get_output\u001b[39m(\n\u001b[1;32m    268\u001b[0m     image,\n\u001b[1;32m    269\u001b[0m     extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m ):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    278\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    288\u001b[0m         run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ml/my_python310_env/lib/python3.10/site-packages/pytesseract/pytesseract.py:197\u001b[0m, in \u001b[0;36msave\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname, realpath(normpath(normcase(image)))\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m image, extension \u001b[38;5;241m=\u001b[39m \u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m input_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    199\u001b[0m image\u001b[38;5;241m.\u001b[39msave(input_file_name, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mformat)\n",
      "File \u001b[0;32m~/ml/my_python310_env/lib/python3.10/site-packages/pytesseract/pytesseract.py:174\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    171\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(image)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, Image\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported image object\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    176\u001b[0m extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;28;01melse\u001b[39;00m image\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_FORMATS:\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported image object"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('test_graham_g.png')\n",
    "\n",
    "# Adding custom options\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "# Convert the image to text\n",
    "text = pytesseract.image_to_string(img, config=custom_config)\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029912de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: If your PDF is mostly clear, high-resolution images of text, direct processing with Tesseract might work well. On the other hand, if you're dealing with complex layouts, vectorized text, or poor-quality scans, you might get better results by first converting the PDF pages to high-quality images using a tool like PyMuPDF (fitz) and then applying OCR to those images. Source: GPT4.  \n",
    "  \n",
    "A more complex example is provided below. We iterate through the pages of a scanned pdf file and extract the corresponding text. You will need an additional library to convert PDF pages to images. PyMuPDF (also known as fitz) is a commonly used library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69519a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = 'Section 165 application.pdf'\n",
    "\n",
    "# Open the PDF file\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Initialize an empty string to accumulate text\n",
    "full_text = \"\"\n",
    "\n",
    "# Frequency of progress updates\n",
    "n = 10\n",
    "\n",
    "# Total number of pages\n",
    "total_pages = len(doc)\n",
    "\n",
    "# Iterate through each page\n",
    "for page_num in range(total_pages):\n",
    "    # Print progress every n pages\n",
    "    if (page_num + 1) % n == 0:\n",
    "        print(f\"Processing page {page_num + 1} of {total_pages}...\")\n",
    "\n",
    "    # Get the page\n",
    "    page = doc.load_page(page_num)\n",
    "\n",
    "    # Convert the page to an image (pix) object\n",
    "    pix = page.get_pixmap()\n",
    "\n",
    "    # Store the image in a format that OpenCV can read (in memory, without saving to disk)\n",
    "    img = cv2.imdecode(np.frombuffer(pix.tobytes(), np.uint8), 1)\n",
    "\n",
    "    # Adding custom options for PyTesseract\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract text using PyTesseract from the current page image\n",
    "    text = pytesseract.image_to_string(img, config=custom_config)\n",
    "    \n",
    "    # Add the extracted text to the full text\n",
    "    full_text += f\"Text from page {page_num + 1}:\\n{text}\\n\\n\"\n",
    "\n",
    "# Close the document\n",
    "doc.close()\n",
    "\n",
    "# Save the full text to a file\n",
    "with open('section_165_ocr_output.txt', 'w') as file:\n",
    "    file.write(full_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0f12f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define image preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8143794",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following code is a Python implementation of some basic image processing techniques.\n",
    "\n",
    "**get_grayscale**\n",
    "\n",
    "This function converts an RGB image to grayscale.\n",
    "\n",
    "**remove_noise**\n",
    "\n",
    "This function removes noise from an image using a median blur filter.\n",
    "\n",
    "**thresholding**\n",
    "\n",
    "This function applies a threshold to an image, converting it to a binary image.\n",
    "\n",
    "**dilation**\n",
    "\n",
    "This function dilates an image, increasing the size of its objects.\n",
    "\n",
    "**erosion**\n",
    "\n",
    "This function erodes an image, decreasing the size of its objects.\n",
    "\n",
    "**opening**\n",
    "\n",
    "This function applies erosion followed by dilation to an image.\n",
    "\n",
    "**canny**\n",
    "\n",
    "This function applies the Canny edge detector to an image.\n",
    "\n",
    "**deskew**\n",
    "\n",
    "This function corrects the skew of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b2c28",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image, threshold_value=128):\n",
    "    # Apply a binary threshold to the image\n",
    "    # The first parameter is the source image, which should be a grayscale image\n",
    "    # The second parameter is the threshold value which is used to classify the pixel values\n",
    "    # The third parameter is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value\n",
    "    # cv2.THRESH_BINARY is the type of threshold applied, and it ensures pixel values are either 0 or maxVal\n",
    "    #return cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)[1] # binary threshold\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] # Otsu's method\n",
    "\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77ddc1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the OCR again with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ffff2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = 'Section 165 application.pdf'\n",
    "\n",
    "# Open the PDF file\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Initialize an empty string to accumulate text\n",
    "full_text = \"\"\n",
    "\n",
    "# Frequency of progress updates\n",
    "n = 10\n",
    "\n",
    "# Total number of pages\n",
    "total_pages = len(doc)\n",
    "\n",
    "# Iterate through each page\n",
    "for page_num in range(total_pages):\n",
    "    # Print progress every n pages\n",
    "    if (page_num + 1) % n == 0:\n",
    "        print(f\"Processing page {page_num + 1} of {total_pages}...\")\n",
    "\n",
    "    # Get the page\n",
    "    page = doc.load_page(page_num)\n",
    "\n",
    "    # Convert the page to an image (pix) object\n",
    "    pix = page.get_pixmap()\n",
    "\n",
    "    # Store the image in a format that OpenCV can read (in memory, without saving to disk)\n",
    "    img = cv2.imdecode(np.frombuffer(pix.tobytes(), np.uint8), 1)\n",
    "    \n",
    "    # Preprocess the images\n",
    "    gray = get_grayscale(img)\n",
    "    thresh = thresholding(gray)\n",
    "    #opened = opening(thresh)\n",
    "    #edged = canny(opened)\n",
    "    #deskewed = deskew(edged)\n",
    "\n",
    "    # Adding custom options for PyTesseract\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract text using PyTesseract from the current page image\n",
    "    text = pytesseract.image_to_string(thresh, config=custom_config)\n",
    "    \n",
    "    # Add the extracted text to the full text\n",
    "    full_text += f\"Text from page {page_num + 1}:\\n{text}\\n\\n\"\n",
    "\n",
    "# Close the document\n",
    "doc.close()\n",
    "\n",
    "# Save the full text to a file\n",
    "with open('section_165_preprocess_ocr_output.txt', 'w') as file:\n",
    "    file.write(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877d6da",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Observation: OCR with Tesseract is not very good. Much of the context is unintelligible. Preprocessing appears to further degrade the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca1bc",
   "metadata": {},
   "source": [
    "#### Run the OCR functions with docTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c6e86",
   "metadata": {},
   "source": [
    "Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50414acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"!pip install pymupdf # converts pdf to high quality images\n",
    "!pip install pillow # image processing\n",
    "!pip install python-doctr #used for ocr\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff15dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight back to Oslo. He didn't know what was going to\n",
      "aRerrou that; the plan he had worked out with Johan Krohn went\n",
      "affer\n",
      "-\n",
      "than this. in the rowlocks and started to row.\n",
      "the oars\n",
      "Peid him. Thought back to the time he used to row while\n",
      "sat in front of him, smiling and giving Harry little bits\n",
      "he should use his upper body and straighten his arms,\n",
      "How stomach, not his biceps. That he should take it gently,never\n",
      "his rhythm, that a boat gliding evenly through the watermoves\n",
      "SS, findar less energy. That he should feel with his buttocks\n",
      "Bster even was sitting in the middle of the bench. That it was all\n",
      "ple sure he That he shouldn't look at the oars, but keep his eyes on\n",
      "aur balance. the signs ofwhat had already happened showed you where\n",
      "kemde heading. But, his grandfather had said, they told you surpris-\n",
      "pus ere about what was going to happen. That was determined by\n",
      "stroke of the oars. His grandfather took out his pocket watch\n",
      "pisidt that when we get back on shore, we look back on our journey\n",
      "saontinuous line from the point of departure to the point of arrival.\n",
      "Asory, with a purpose and a direction. We remember it as if it were\n",
      "k,a and nowhere but here, that we intended the boat to meet the shore-\n",
      "h he said. But the point of arrival and the intended destination were\n",
      "modiferent things. Not that one was necessarily better than the other.\n",
      "Rget to where we get to, and it can be a consolation to believe that\n",
      "Bwhere we wanted to get to, or at least were on our way towards the\n",
      "tet time. But our fallible memories are like a kind mother telling us\n",
      "T dever we are, that our strokes with the oar were clean and fitted\n",
      "btes story as a logical, intentional part. The idea that we may have\n",
      "Redf course, that we no longer know where we are or where we\n",
      "-\n",
      "with\n",
      "to\n",
      "that\n",
      "spr litle\n",
      "kenets\n",
      "ig that life is a chaotic\n",
      "Paling that we\n",
      "Ppe\n",
      "who\n",
      "tte\n",
      "mess of clumsy, fumbled oar strokes, is\n",
      "prefer to rewrite the story in hindsight. That's\n",
      "Miden appear to have been successful and are asked to talk\n",
      "VEe Say it was the\n",
      "dream - the only one - they'd had since\n",
      "to succeed in whatever it\n",
      "was that they had been\n",
      "517\n"
     ]
    }
   ],
   "source": [
    "# Experiment with one image\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "# Load a document\n",
    "doc = DocumentFile.from_images('harry.jpeg')\n",
    "\n",
    "# Load the OCR model\n",
    "model = ocr_predictor(pretrained=True)\n",
    "\n",
    "# Perform OCR on the document\n",
    "result = model(doc)\n",
    "\n",
    "# The result is a structured document\n",
    "for page in result.pages:\n",
    "    for block in page.blocks:\n",
    "        for line in block.lines:\n",
    "            # Concatenate words in the line to form a sentence\n",
    "            line_text = ' '.join(word.value for word in line.words)\n",
    "            print(line_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3796568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 5 of 9...\n",
      "Preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# Convert an entire pdf\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = './georg/pdfs/Notice of Motion (Long Form) issued_LPC RAF 180 DAYS 2024.pdf'\n",
    "\n",
    "# Output file path\n",
    "output_file = 'Notice_Long_ocr_doctr.txt'\n",
    "\n",
    "# Open the PDF file\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Initialize the OCR model\n",
    "model = ocr_predictor(pretrained=True)\n",
    "\n",
    "# Initialize a variable to store the full text\n",
    "full_text = \"\"\n",
    "\n",
    "# Frequency of progress updates\n",
    "n = 5\n",
    "\n",
    "# Total number of pages\n",
    "total_pages = len(doc)\n",
    "\n",
    "# Iterate through each page of the PDF\n",
    "for page_num in range(len(doc)):\n",
    "    # Print progress every n pages\n",
    "    if (page_num + 1) % n == 0:\n",
    "        print(f\"Processing page {page_num + 1} of {total_pages}...\")\n",
    "        \n",
    "    # Get the page\n",
    "    page = doc.load_page(page_num)\n",
    "\n",
    "    # Convert the page to a PIL image\n",
    "    pix = page.get_pixmap()\n",
    "    img_bytes = BytesIO(pix.tobytes(\"png\"))\n",
    "    image = Image.open(img_bytes)\n",
    "\n",
    "    # Convert PIL image to byte array\n",
    "    image_byte_array = BytesIO()\n",
    "    image.save(image_byte_array, format='PNG')\n",
    "    image_byte_array = image_byte_array.getvalue()\n",
    "\n",
    "    # Perform OCR on the image\n",
    "    result = model(DocumentFile.from_images([image_byte_array]))\n",
    "\n",
    "    # Process the result\n",
    "    for doc_page in result.pages:\n",
    "        for block in doc_page.blocks:\n",
    "            for line in block.lines:\n",
    "                line_text = ' '.join(word.value for word in line.words)\n",
    "                full_text += line_text + '\\n'\n",
    "\n",
    "# Close the document\n",
    "doc.close()\n",
    "\n",
    "# Save the full text to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(full_text)\n",
    "    print(\"Preprocessing complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa9dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169ccb3a",
   "metadata": {},
   "source": [
    "Explain the code using Google PaLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad70e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste in the code block\n",
    "\n",
    "CODE_BLOCK=\"\"\"\n",
    "# Convert an entire pdf\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = 'Section 165 application.pdf'\n",
    "\n",
    "# Output file path\n",
    "output_file = 'section_165_ocr_doctr.txt'\n",
    "\n",
    "# Open the PDF file\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Initialize the OCR model\n",
    "model = ocr_predictor(pretrained=True)\n",
    "\n",
    "# Initialize a variable to store the full text\n",
    "full_text = \"\"\n",
    "\n",
    "# Frequency of progress updates\n",
    "n = 10\n",
    "\n",
    "# Total number of pages\n",
    "total_pages = len(doc)\n",
    "\n",
    "# Iterate through each page of the PDF\n",
    "for page_num in range(len(doc)):\n",
    "    # Print progress every n pages\n",
    "    if (page_num + 1) % n == 0:\n",
    "        print(f\"Processing page {page_num + 1} of {total_pages}...\")\n",
    "        \n",
    "    # Get the page\n",
    "    page = doc.load_page(page_num)\n",
    "\n",
    "    # Convert the page to a PIL image\n",
    "    pix = page.get_pixmap()\n",
    "    img_bytes = BytesIO(pix.tobytes(\"png\"))\n",
    "    image = Image.open(img_bytes)\n",
    "\n",
    "    # Convert PIL image to byte array\n",
    "    image_byte_array = BytesIO()\n",
    "    image.save(image_byte_array, format='PNG')\n",
    "    image_byte_array = image_byte_array.getvalue()\n",
    "\n",
    "    # Perform OCR on the image\n",
    "    result = model(DocumentFile.from_images([image_byte_array]))\n",
    "\n",
    "    # Process the result\n",
    "    for doc_page in result.pages:\n",
    "        for block in doc_page.blocks:\n",
    "            for line in block.lines:\n",
    "                line_text = ' '.join(word.value for word in line.words)\n",
    "                full_text += line_text + '\\n'\n",
    "\n",
    "# Close the document\n",
    "doc.close()\n",
    "\n",
    "# Save the full text to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(full_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "397d7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the prompt\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Can you please explain how this code works?\n",
    "\n",
    "{question}\n",
    "\n",
    "Use a lot of detail and make it as clear as possible.\n",
    "Output the results in markdown\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6e01a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following code is a Python implementation of some basic image processing techniques.\n",
      "\n",
      "**get_grayscale**\n",
      "\n",
      "This function converts an RGB image to grayscale.\n",
      "\n",
      "**remove_noise**\n",
      "\n",
      "This function removes noise from an image using a median blur filter.\n",
      "\n",
      "**thresholding**\n",
      "\n",
      "This function applies a threshold to an image, converting it to a binary image.\n",
      "\n",
      "**dilation**\n",
      "\n",
      "This function dilates an image, increasing the size of its objects.\n",
      "\n",
      "**erosion**\n",
      "\n",
      "This function erodes an image, decreasing the size of its objects.\n",
      "\n",
      "**opening**\n",
      "\n",
      "This function applies erosion followed by dilation to an image.\n",
      "\n",
      "**canny**\n",
      "\n",
      "This function applies the Canny edge detector to an image.\n",
      "\n",
      "**deskew**\n",
      "\n",
      "This function corrects the skew of an image.\n",
      "\n",
      "**Output**\n",
      "\n",
      "The following is the output of the code on an example image:\n",
      "\n",
      "```\n",
      "[![Image of the output](https://i.imgur.com/0311111.png)](https://i.imgur.com/0311111.png)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Run the completion\n",
    "\n",
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=CODE_BLOCK)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b036f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375f964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
