{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43d1926-71b7-4689-8547-84f7576f3c49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Grading Student Essays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad80222-badc-4285-a37a-1ea5e94df7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook, I finetune a sequence classifier model from Hugging Face using the [Hewlett Foundation scored essay data set](https://www.kaggle.com/competitions/asap-aes/data).  \n",
    "This dataset is taken from the training_set_rel3.xlsx on Kaggle. \n",
    "After changing the continuous scores to categories, the task is treated as a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c28cb9-3dba-46b5-9829-9a360d45ca53",
   "metadata": {},
   "source": [
    "### 1 - Install and load required dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddf4fe4-3807-4f5c-a2ad-84bbec5d4c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\n",
      "pathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    loralib==0.1.1 --quiet\n",
    "\n",
    "%pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e7bdcc-bb8f-442a-b7f8-49b706dcca8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ef7fb-6d3d-41a1-83d0-ee9d660007fb",
   "metadata": {},
   "source": [
    "## 2 - Define a DataSet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a014c-e20f-441f-b47e-e3b9d017117d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "class EssayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, essays, grades):\n",
    "        self.essays = essays\n",
    "        self.grades = grades\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.essays)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        essay = self.essays[idx]\n",
    "        grade = self.grades[idx]\n",
    "        tokens = self.tokenizer(essay, truncation=True, padding='max_length', max_length=512)\n",
    "        return {key: torch.tensor(val, dtype=torch.long) for key, val in tokens.items()}, torch.tensor(grade, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af0fc5-3926-4b18-a297-1246bb979553",
   "metadata": {},
   "source": [
    "### 3 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c925743-ef2d-4c60-ab82-57bf6dc270e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-635f8d9d43b9c06c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7be96b006524ec2ab4af41a18c14878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'essay', 'category'],\n",
      "        num_rows: 12978\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files='categorised_essays.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b1a66-f9c3-4cd6-a96e-676f7f567f5b",
   "metadata": {},
   "source": [
    "#### 3.1 Encode the labels as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f122f9c-4143-4484-91f5-2b645b2fd6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-635f8d9d43b9c06c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-55ab6ca522103b74.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'essay', 'category', 'encoded_labels'],\n",
      "        num_rows: 12978\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "\n",
    "# Instantiate the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Function to encode the labels within the 'map' method\n",
    "def encode_labels(example):\n",
    "    example['encoded_labels'] = label_encoder.transform([example['category']])[0]\n",
    "    return example\n",
    "\n",
    "# Fit the LabelEncoder on the categories\n",
    "label_encoder.fit(dataset['train']['category'])\n",
    "\n",
    "# Use the 'map' function to apply the encoding to each example\n",
    "dataset['train'] = dataset['train'].map(encode_labels, batched=False)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbec697-5f1a-4f06-8e6a-daed5b9cfa91",
   "metadata": {},
   "source": [
    "#### 3.2 Save the label encoder so you can inverse transform the predictions later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42209c0-3ae2-4b30-9761-c90a3341d3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the fitted LabelEncoder to a file so you can load it again and apply the inverse transform\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "# Later on, or in another script, you can load it back\n",
    "#label_encoder = joblib.load('label_encoder.joblib')\n",
    "\n",
    "# And then use it to inverse transform your predictions\n",
    "#predicted_categories = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bcc14-c9b4-434b-b69c-a38b92871a65",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.3 - Shuffle and sample a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76245a47-70ae-45b5-9e93-42cc99b10b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-635f8d9d43b9c06c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-203d54942b8fa79c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['essay_id', 'essay', 'category', 'encoded_labels'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset\n",
    "shuffled_dataset = dataset['train'].shuffle(seed=42)\n",
    "\n",
    "# Select n random samples\n",
    "n_samples = 2000\n",
    "scored_essays = shuffled_dataset.select(range(n_samples))\n",
    "\n",
    "print(scored_essays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4954fc1-f0ef-4ae0-8c42-b744262057f8",
   "metadata": {},
   "source": [
    "#### 3.4 - Extract the essays and grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c71d5e3-613b-4ca3-9dee-df6fb5ac822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essays = scored_essays['essay'] # list of essay strings\n",
    "grades = scored_essays['encoded_labels'] # list of categorical grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ee900-dad5-4e1a-b203-3bf3e55e7eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0e7509-be66-41dc-96d2-bd460659c785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and temporary sets (80/20 split)\n",
    "essays_train, essays_temp, grades_train, grades_temp = train_test_split(\n",
    "    essays, grades, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets (50/50 split)\n",
    "essays_val, essays_test, grades_val, grades_test = train_test_split(\n",
    "    essays_temp, grades_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a7507-3546-4b9e-9be1-a742ae3ffc28",
   "metadata": {},
   "source": [
    "### 4 - Tokenize the data  \n",
    "Create a dataset where each item is a tuple containing the tokenized essay and the corresponding categorical grade.  \n",
    "These datasets can then be used to create DataLoaders which will handle batching of data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157f9051-5b8f-441e-a2bb-de8a026c540f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = EssayDataset(essays_train, grades_train)\n",
    "val_dataset = EssayDataset(essays_val, grades_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ad8cc-dafe-4a69-8c5b-b6ed35873f69",
   "metadata": {},
   "source": [
    "#### 4.1 - Initialize the original model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe49bd43-c526-4c49-84ae-ae9ee5c48688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_classes = 6\n",
    "original_model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,  # this is the number of classes\n",
    "    problem_type=\"single_label_classification\"  # make sure to set this for single-label classification\n",
    ")\n",
    "\n",
    "optimizer = AdamW(original_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1fe95-3fa1-42e3-b850-d7fe89a3dfbe",
   "metadata": {},
   "source": [
    "#### 4.2 - Print the number of trainable model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918a4389-6dd9-4a39-81fd-fbef1484a175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 109486854\n",
      "all model parameters: 109486854\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb580252-1972-481c-8e97-de20b8704ace",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5 - Full fine tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0af371-2517-4779-9a0d-0d173663e7ac",
   "metadata": {},
   "source": [
    "Train for 1 epoch to ensure the training and validation steps work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f44c28c-859b-4e4e-ae0a-a753bc3d3ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss: 0.4019169419631362\n",
      "Epoch 1, Validation loss: 0.45629968523979186\n",
      "Validation Accuracy: 0.825\n",
      "Validation loss decreased from inf to 0.45629968523979186. Saving model to ./full-finetune-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      0.95      0.98        21\n",
      "           B       0.82      0.86      0.84        21\n",
      "           C       0.84      0.80      0.82        20\n",
      "           D       0.90      0.88      0.89        69\n",
      "           E       0.51      0.74      0.61        27\n",
      "           F       0.94      0.71      0.81        42\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.82      0.82       200\n",
      "weighted avg       0.85      0.82      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import copy\n",
    "\n",
    "n_epochs = 1  # Set a higher number of epochs to take advantage of early stopping\n",
    "patience = 2  # Number of epochs to wait for improvement before stopping\n",
    "patience_counter = 0  # To keep track of how many epochs without improvement\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "original_model_path = './full-finetune-essay-categories' # Define a path to save the model\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    original_model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Unpack the tokenized tensors and encoded labels from the batch\n",
    "        tokenized_tensors = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        # Extract the tokenized tensors\n",
    "        input_ids = tokenized_tensors['input_ids']\n",
    "        attention_mask = tokenized_tensors['attention_mask']\n",
    "        \n",
    "        # Convert labels to long integers\n",
    "        labels = labels.long()\n",
    "\n",
    "        # Forward pass with labels to compute loss\n",
    "        outputs = original_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}, Training loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    original_model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            # Unpack the tokenized tensors and labels from the batch\n",
    "            tokenized_tensors = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            input_ids = tokenized_tensors['input_ids']\n",
    "            attention_mask = tokenized_tensors['attention_mask']\n",
    "\n",
    "            # Convert labels to long integers\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Forward pass, we don't provide labels during inference\n",
    "            outputs = original_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            val_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f'Epoch {epoch + 1}, Validation loss: {avg_val_loss}')\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    report = classification_report(val_labels, val_preds, target_names=label_encoder.classes_)\n",
    "    print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "    # Save model if validation loss has improved\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        print(f'Validation loss decreased from {best_val_loss} to {avg_val_loss}. Saving model to {original_model_path}')\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = copy.deepcopy(original_model.state_dict())\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model to disk\n",
    "        # First ensure the best model weights are loaded\n",
    "        original_model.load_state_dict(best_model)\n",
    "\n",
    "        # Save model weights\n",
    "        original_model.save_pretrained(original_model_path)\n",
    "\n",
    "        # Save tokenizer from the train_dataset\n",
    "        train_dataset.tokenizer.save_pretrained(original_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation loss did not improve. Patience: {patience_counter}/{patience}')\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec38dd-9631-4f9c-86af-e39fbf892da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the best model and the corresponding tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6435ddb3-0b54-45ca-b86e-1ae0dc1c4381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./full-finetune-essay-categories/tokenizer_config.json',\n",
       " './full-finetune-essay-categories/special_tokens_map.json',\n",
       " './full-finetune-essay-categories/vocab.txt',\n",
       " './full-finetune-essay-categories/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the best model weights are loaded\n",
    "original_model.load_state_dict(best_model)\n",
    "\n",
    "# Save model weights\n",
    "original_model.save_pretrained(original_model_path)\n",
    "\n",
    "# Save tokenizer from the train_dataset\n",
    "train_dataset.tokenizer.save_pretrained(original_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f1af2-4720-495b-8cd2-8e8f08525cea",
   "metadata": {},
   "source": [
    "Optional: Reload model and tokenizer from file when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdf013fe-7f98-4f00-88e8-8b76d7a25b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_model = BertForSequenceClassification.from_pretrained(original_model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(original_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60039e-d3b4-47d7-a00f-1d04bd99f83c",
   "metadata": {},
   "source": [
    "### 6 - Parameter efficient fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c9833-b1e9-414c-bf2a-e3d05f181d5d",
   "metadata": {},
   "source": [
    "#### 6.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
    "\n",
    "Performing full-finetuning can lead to catastrophic forgetting because it changes all parameters on the model. Since PEFT only updates a small subset of parameters, it's more robust against this catastrophic forgetting effect.\n",
    "\n",
    "Set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10b388af-0a15-47ee-97ff-e4f688d3034b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft==0.3.0 --quiet\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.self.query\", \"attention.self.value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS # Sequence classificatio task\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c927b-7aee-4cb9-b1b9-4b7a1d99cb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.2 - Add LoRA adapter layers/parameters to the original LLM to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c9bbd6f-e4f5-436c-b8da-b58c65983e58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 1179648\n",
      "all model parameters: 110671116\n",
      "percentage of trainable model parameters: 1.07%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model, lora_config)\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e1d4c-b2b6-485e-a7bb-1fe7926ba97c",
   "metadata": {},
   "source": [
    "#### 6.3 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c368380-e1d4-40bd-baf0-2670e91934ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss: 1.54435546875\n",
      "Epoch 1, Validation loss: 1.34453125\n",
      "Validation Accuracy: 0.455\n",
      "Validation loss decreased from inf to 1.34453125. Saving model to ./peft-essay-categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.60      0.14      0.23        21\n",
      "           B       0.00      0.00      0.00        21\n",
      "           C       0.50      0.40      0.44        20\n",
      "           D       0.50      0.97      0.66        69\n",
      "           E       0.17      0.22      0.19        27\n",
      "           F       0.78      0.17      0.27        42\n",
      "\n",
      "    accuracy                           0.46       200\n",
      "   macro avg       0.42      0.32      0.30       200\n",
      "weighted avg       0.47      0.46      0.38       200\n",
      "\n",
      "Epoch 2, Training loss: 1.34390625\n",
      "Epoch 2, Validation loss: 1.2125\n",
      "Validation Accuracy: 0.555\n",
      "Validation loss decreased from 1.34453125 to 1.2125. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      0.10      0.17        21\n",
      "           B       0.61      0.52      0.56        21\n",
      "           C       0.75      0.30      0.43        20\n",
      "           D       0.55      0.96      0.70        69\n",
      "           E       0.29      0.37      0.33        27\n",
      "           F       0.84      0.38      0.52        42\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.68      0.44      0.45       200\n",
      "weighted avg       0.65      0.56      0.52       200\n",
      "\n",
      "Epoch 3, Training loss: 1.24919921875\n",
      "Epoch 3, Validation loss: 1.2021875\n",
      "Validation Accuracy: 0.515\n",
      "Validation loss decreased from 1.2125 to 1.2021875. Saving model to ./peft-essay-categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.14      0.24        21\n",
      "           B       0.00      0.00      0.00        21\n",
      "           C       0.52      0.65      0.58        20\n",
      "           D       0.60      0.86      0.71        69\n",
      "           E       0.24      0.48      0.32        27\n",
      "           F       0.79      0.36      0.49        42\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.48      0.41      0.39       200\n",
      "weighted avg       0.54      0.52      0.47       200\n",
      "\n",
      "Epoch 4, Training loss: 1.1851171875\n",
      "Epoch 4, Validation loss: 1.07890625\n",
      "Validation Accuracy: 0.615\n",
      "Validation loss decreased from 1.2021875 to 1.07890625. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.92      0.52      0.67        21\n",
      "           B       0.67      0.29      0.40        21\n",
      "           C       0.39      0.75      0.52        20\n",
      "           D       0.66      0.74      0.70        69\n",
      "           E       0.44      0.26      0.33        27\n",
      "           F       0.69      0.79      0.73        42\n",
      "\n",
      "    accuracy                           0.61       200\n",
      "   macro avg       0.63      0.56      0.56       200\n",
      "weighted avg       0.64      0.61      0.60       200\n",
      "\n",
      "Epoch 5, Training loss: 1.148837890625\n",
      "Epoch 5, Validation loss: 1.08859375\n",
      "Validation Accuracy: 0.6\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      0.10      0.17        21\n",
      "           B       0.69      0.52      0.59        21\n",
      "           C       0.65      0.65      0.65        20\n",
      "           D       0.54      0.96      0.69        69\n",
      "           E       0.14      0.04      0.06        27\n",
      "           F       0.84      0.64      0.73        42\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.64      0.48      0.48       200\n",
      "weighted avg       0.62      0.60      0.54       200\n",
      "\n",
      "Epoch 6, Training loss: 1.1049609375\n",
      "Epoch 6, Validation loss: 1.08359375\n",
      "Validation Accuracy: 0.585\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.72      0.62      0.67        21\n",
      "           B       1.00      0.05      0.09        21\n",
      "           C       0.48      0.75      0.59        20\n",
      "           D       0.65      0.88      0.75        69\n",
      "           E       0.28      0.37      0.32        27\n",
      "           F       0.85      0.40      0.55        42\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.66      0.51      0.49       200\n",
      "weighted avg       0.67      0.58      0.55       200\n",
      "\n",
      "Epoch 7, Training loss: 1.080771484375\n",
      "Epoch 7, Validation loss: 1.0853125\n",
      "Validation Accuracy: 0.575\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.80      0.57      0.67        21\n",
      "           B       0.71      0.57      0.63        21\n",
      "           C       1.00      0.30      0.46        20\n",
      "           D       0.55      0.96      0.70        69\n",
      "           E       0.19      0.19      0.19        27\n",
      "           F       0.88      0.33      0.48        42\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.69      0.49      0.52       200\n",
      "weighted avg       0.66      0.57      0.55       200\n",
      "\n",
      "Epoch 8, Training loss: 1.07572265625\n",
      "Epoch 8, Validation loss: 1.030703125\n",
      "Validation Accuracy: 0.585\n",
      "Validation loss decreased from 1.07890625 to 1.030703125. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.64      0.76      0.70        21\n",
      "           B       0.00      0.00      0.00        21\n",
      "           C       0.86      0.30      0.44        20\n",
      "           D       0.53      0.94      0.68        69\n",
      "           E       0.00      0.00      0.00        27\n",
      "           F       0.71      0.71      0.71        42\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.46      0.45      0.42       200\n",
      "weighted avg       0.49      0.58      0.50       200\n",
      "\n",
      "Epoch 9, Training loss: 1.048056640625\n",
      "Epoch 9, Validation loss: 0.989375\n",
      "Validation Accuracy: 0.6\n",
      "Validation loss decreased from 1.030703125 to 0.989375. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.68      0.62      0.65        21\n",
      "           B       0.50      0.05      0.09        21\n",
      "           C       0.68      0.65      0.67        20\n",
      "           D       0.57      0.94      0.71        69\n",
      "           E       0.17      0.07      0.10        27\n",
      "           F       0.79      0.62      0.69        42\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.56      0.49      0.48       200\n",
      "weighted avg       0.58      0.60      0.55       200\n",
      "\n",
      "Epoch 10, Training loss: 1.04916015625\n",
      "Epoch 10, Validation loss: 1.0515625\n",
      "Validation Accuracy: 0.6\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.93      0.62      0.74        21\n",
      "           B       0.61      0.67      0.64        21\n",
      "           C       1.00      0.40      0.57        20\n",
      "           D       0.65      0.88      0.75        69\n",
      "           E       0.29      0.56      0.38        27\n",
      "           F       0.90      0.21      0.35        42\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.73      0.56      0.57       200\n",
      "weighted avg       0.71      0.60      0.58       200\n",
      "\n",
      "Epoch 11, Training loss: 1.0151953125\n",
      "Epoch 11, Validation loss: 1.045859375\n",
      "Validation Accuracy: 0.575\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.82      0.43      0.56        21\n",
      "           B       0.75      0.14      0.24        21\n",
      "           C       0.65      0.65      0.65        20\n",
      "           D       0.53      0.96      0.68        69\n",
      "           E       0.22      0.15      0.18        27\n",
      "           F       0.87      0.48      0.62        42\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.64      0.47      0.49       200\n",
      "weighted avg       0.63      0.57      0.54       200\n",
      "\n",
      "Epoch 12, Training loss: 1.002734375\n",
      "Epoch 12, Validation loss: 0.963046875\n",
      "Validation Accuracy: 0.63\n",
      "Validation loss decreased from 0.989375 to 0.963046875. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.64      0.76      0.70        21\n",
      "           B       0.75      0.14      0.24        21\n",
      "           C       0.58      0.70      0.64        20\n",
      "           D       0.61      0.93      0.74        69\n",
      "           E       0.18      0.07      0.11        27\n",
      "           F       0.87      0.64      0.74        42\n",
      "\n",
      "    accuracy                           0.63       200\n",
      "   macro avg       0.61      0.54      0.53       200\n",
      "weighted avg       0.62      0.63      0.59       200\n",
      "\n",
      "Epoch 13, Training loss: 1.01501953125\n",
      "Epoch 13, Validation loss: 0.925625\n",
      "Validation Accuracy: 0.65\n",
      "Validation loss decreased from 0.963046875 to 0.925625. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.68      0.71      0.70        21\n",
      "           B       0.77      0.48      0.59        21\n",
      "           C       1.00      0.45      0.62        20\n",
      "           D       0.61      0.94      0.74        69\n",
      "           E       0.33      0.30      0.31        27\n",
      "           F       0.88      0.55      0.68        42\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.71      0.57      0.61       200\n",
      "weighted avg       0.69      0.65      0.64       200\n",
      "\n",
      "Epoch 14, Training loss: 0.97296875\n",
      "Epoch 14, Validation loss: 0.981875\n",
      "Validation Accuracy: 0.645\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.93      0.62      0.74        21\n",
      "           B       0.79      0.52      0.63        21\n",
      "           C       0.58      0.70      0.64        20\n",
      "           D       0.74      0.80      0.77        69\n",
      "           E       0.35      0.70      0.46        27\n",
      "           F       0.89      0.40      0.56        42\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.71      0.62      0.63       200\n",
      "weighted avg       0.73      0.65      0.65       200\n",
      "\n",
      "Epoch 15, Training loss: 1.0140625\n",
      "Epoch 15, Validation loss: 0.896640625\n",
      "Validation Accuracy: 0.675\n",
      "Validation loss decreased from 0.925625 to 0.896640625. Saving model to ./peft-essay-categories\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.68      0.71      0.70        21\n",
      "           B       0.64      0.33      0.44        21\n",
      "           C       0.70      0.70      0.70        20\n",
      "           D       0.68      0.93      0.79        69\n",
      "           E       0.38      0.37      0.38        27\n",
      "           F       0.93      0.60      0.72        42\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.67      0.61      0.62       200\n",
      "weighted avg       0.69      0.68      0.66       200\n",
      "\n",
      "Epoch 16, Training loss: 0.983173828125\n",
      "Epoch 16, Validation loss: 0.99359375\n",
      "Validation Accuracy: 0.615\n",
      "Validation loss did not improve. Patience: 1/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.67      0.67        21\n",
      "           B       0.71      0.24      0.36        21\n",
      "           C       0.92      0.60      0.73        20\n",
      "           D       0.66      0.88      0.76        69\n",
      "           E       0.33      0.63      0.43        27\n",
      "           F       0.93      0.33      0.49        42\n",
      "\n",
      "    accuracy                           0.61       200\n",
      "   macro avg       0.70      0.56      0.57       200\n",
      "weighted avg       0.71      0.61      0.60       200\n",
      "\n",
      "Epoch 17, Training loss: 0.996201171875\n",
      "Epoch 17, Validation loss: 0.938515625\n",
      "Validation Accuracy: 0.635\n",
      "Validation loss did not improve. Patience: 2/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.69      0.86      0.77        21\n",
      "           B       0.80      0.19      0.31        21\n",
      "           C       0.52      0.70      0.60        20\n",
      "           D       0.69      0.87      0.77        69\n",
      "           E       0.31      0.37      0.34        27\n",
      "           F       0.91      0.50      0.65        42\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.65      0.58      0.57       200\n",
      "weighted avg       0.68      0.64      0.62       200\n",
      "\n",
      "Epoch 18, Training loss: 0.990576171875\n",
      "Epoch 18, Validation loss: 0.9284375\n",
      "Validation Accuracy: 0.665\n",
      "Validation loss did not improve. Patience: 3/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.87      0.62      0.72        21\n",
      "           B       0.60      0.57      0.59        21\n",
      "           C       0.64      0.70      0.67        20\n",
      "           D       0.75      0.80      0.77        69\n",
      "           E       0.38      0.67      0.49        27\n",
      "           F       0.91      0.50      0.65        42\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.69      0.64      0.65       200\n",
      "weighted avg       0.72      0.67      0.67       200\n",
      "\n",
      "Epoch 19, Training loss: 0.968583984375\n",
      "Epoch 19, Validation loss: 0.91703125\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation Accuracy: 0.64\n",
      "Validation loss did not improve. Patience: 4/5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.65      0.81      0.72        21\n",
      "           B       0.83      0.24      0.37        21\n",
      "           C       0.92      0.60      0.73        20\n",
      "           D       0.59      0.94      0.72        69\n",
      "           E       0.23      0.11      0.15        27\n",
      "           F       0.84      0.62      0.71        42\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.68      0.55      0.57       200\n",
      "weighted avg       0.66      0.64      0.61       200\n",
      "\n",
      "Epoch 20, Training loss: 0.955390625\n",
      "Epoch 20, Validation loss: 0.90375\n",
      "Validation Accuracy: 0.65\n",
      "Validation loss did not improve. Patience: 5/5\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import copy\n",
    "\n",
    "n_epochs = 20  # Set a higher number of epochs for early stopping\n",
    "patience = 5  # Number of epochs to wait for improvement before stopping\n",
    "patience_counter = 0  # To keep track of how many epochs without improvement\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "peft_model_path = './peft-essay-categories' # Define a path to save the model\n",
    "optimizer = AdamW(peft_model.parameters(), lr=1e-3) # Higher learning rate than full fine tuning\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    peft_model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Unpack the tokenized tensors and encoded labels from the batch\n",
    "        tokenized_tensors = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        # Extract the tokenized tensors\n",
    "        input_ids = tokenized_tensors['input_ids']\n",
    "        attention_mask = tokenized_tensors['attention_mask']\n",
    "        \n",
    "        # Convert labels to long integers\n",
    "        labels = labels.long()\n",
    "\n",
    "        # Forward pass with labels to compute loss\n",
    "        outputs = peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}, Training loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    peft_model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            # Unpack the tokenized tensors and labels from the batch\n",
    "            tokenized_tensors = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            input_ids = tokenized_tensors['input_ids']\n",
    "            attention_mask = tokenized_tensors['attention_mask']\n",
    "\n",
    "            # Convert labels to long integers\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Forward pass, we don't provide labels during inference\n",
    "            outputs = peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            val_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f'Epoch {epoch + 1}, Validation loss: {avg_val_loss}')\n",
    "    \n",
    "    # Step the scheduler with the validation loss\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    report = classification_report(val_labels, val_preds, target_names=label_encoder.classes_)\n",
    "    print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "    # Save model if validation loss has improved\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        print(f'Validation loss decreased from {best_val_loss} to {avg_val_loss}. Saving model to {peft_model_path}')\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = copy.deepcopy(peft_model.state_dict())\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model to disk\n",
    "        # First ensure the best model weights are loaded\n",
    "        peft_model.load_state_dict(best_model)\n",
    "\n",
    "        # Save model weights\n",
    "        peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "        # Save tokenizer from the train_dataset\n",
    "        train_dataset.tokenizer.save_pretrained(peft_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation loss did not improve. Patience: {patience_counter}/{patience}')\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "            \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaba6c-2e0d-4c8a-840c-dbab9adc5840",
   "metadata": {},
   "source": [
    "#### Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e51463-5035-4ea1-8130-87bec8306366",
   "metadata": {},
   "source": [
    "In the context of grading essays using a fine-tuned language model, the relative importance of precision and recall may depend on the specific objectives and consequences of the grading system.\n",
    "\n",
    "Here are some considerations:\n",
    "\n",
    "1. **Precision (Positive Predictive Value)**: Precision measures the accuracy of the positive predictions. In essay grading, a high precision would mean that when the model assigns a specific grade, it is usually correct. This is important when you want to ensure that students are only awarded a certain grade if their essays truly merit it. For example, if precision is crucial, you wouldn't want to give an \"A\" to a student unless you are quite certain their work deserves an \"A\".\n",
    "\n",
    "2. **Recall (Sensitivity)**: Recall measures the ability of the model to find all the relevant cases (all the essays that truly deserve a particular grade). High recall in essay grading means that most essays that deserve a certain grade are correctly identified and assigned that grade by the model. This is important when it is crucial to identify all the students who deserve a particular grade. For instance, if every student who deserves an \"A\" must receive one, then recall is vital.\n",
    "\n",
    "Depending on the context, you might prioritize differently:\n",
    "\n",
    "- **If you are more concerned about fairness and equality**, you might prioritize recall to ensure that every student who deserves a high grade receives it, minimizing the chances that a high-quality essay is graded too harshly.\n",
    "- **If you are more concerned about maintaining high standards**, you might prioritize precision to ensure that only truly outstanding essays receive the highest grades, minimizing the chances that a lower-quality essay is graded too leniently.\n",
    "\n",
    "In many educational contexts, a balance between precision and recall is sought. This balance can be measured by the F1 score, which is the harmonic mean of precision and recall. The F1 score provides a single metric that takes into account both the precision and the recall. This is useful when you need to ensure that the grading model is both accurate and fair in assigning grades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda7e6a-ffa9-439b-a18d-a66191d0a4b6",
   "metadata": {},
   "source": [
    "#### 6.4 - Save the final best model and the corresponding tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0702c218-10ba-431f-8729-48d22f821811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-essay-categories/tokenizer_config.json',\n",
       " './peft-essay-categories/special_tokens_map.json',\n",
       " './peft-essay-categories/vocab.txt',\n",
       " './peft-essay-categories/added_tokens.json')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the best model weights are loaded\n",
    "peft_model.load_state_dict(best_model)\n",
    "\n",
    "# Save model weights\n",
    "peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "# Save tokenizer from the train_dataset\n",
    "train_dataset.tokenizer.save_pretrained(peft_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce46479-2196-4867-b975-2d3fbd65f56a",
   "metadata": {},
   "source": [
    "### 7 - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1185701-56e8-4bec-bac4-af00df418518",
   "metadata": {},
   "source": [
    "#### 7.1 - Prepare this model by adding an adapter to the original model.   \n",
    "Set is_trainable=False because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set is_trainable=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e9e73d0-a705-43de-be8e-9ecb1c17b212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, torch_dtype=torch.bfloat16)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       peft_model_path, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       num_labels=num_classes,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10883037-14df-4fd7-9b18-e1a1e1d4028f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.2 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "Make inferences with the original model and PEFT model for one test instance initially.  \n",
    "Please note the original model would normally be the fully fine tuned model.  \n",
    "I have not fine tuned the original model fully to conserve resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8b562d37-a0ea-484a-a38e-cf74539954ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL CATEGORY: F\n",
      "ORIGINAL MODEL PREDICTED CATEGORY: E\n",
      "PEFT MODEL PREDICTED CATEGORY: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "\n",
    "essay = essays_test[index]\n",
    "category_label = grades_test[index]  # Assuming this is the original encoded category label\n",
    "\n",
    "# Prepare the prompt and tokenize\n",
    "prompt = f\"Assign a score to the following essay:\\n\\n{essay}\\n\\nScore:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Move tensors to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Make sure your models are in evaluation mode\n",
    "original_model.eval()\n",
    "peft_model.eval()\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    # Get model predictions\n",
    "    original_model_outputs = original_model(**inputs)\n",
    "    peft_model_outputs = peft_model(**inputs)\n",
    "\n",
    "    # Extract the predicted class index from the outputs\n",
    "    original_model_pred_index = torch.argmax(original_model_outputs.logits, dim=-1)\n",
    "    peft_model_pred_index = torch.argmax(peft_model_outputs.logits, dim=-1)\n",
    "\n",
    "    # Convert predicted indices to class labels using the label encoder\n",
    "    original_model_label = label_encoder.inverse_transform([original_model_pred_index.cpu().numpy()])[0]\n",
    "    peft_model_label = label_encoder.inverse_transform([peft_model_pred_index.cpu().numpy()])[0]\n",
    "    category_label_true = label_encoder.inverse_transform([category_label])[0]\n",
    "    \n",
    "\n",
    "# Print results\n",
    "print(f\"ACTUAL CATEGORY: {category_label_true.item()}\")\n",
    "print(f\"ORIGINAL MODEL PREDICTED CATEGORY: {original_model_label}\")\n",
    "print(f\"PEFT MODEL PREDICTED CATEGORY: {peft_model_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1993a-7744-414e-ade5-a09af520df3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.3 - Evaluate the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5f1bf57-b7f8-4806-b01c-479cc376460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping essay 5 with length 766...\n",
      "Processing batch 10/200\n",
      "Skipping essay 11 with length 834...\n",
      "Skipping essay 20 with length 720...\n",
      "Processing batch 30/200\n",
      "Skipping essay 37 with length 624...\n",
      "Processing batch 40/200\n",
      "Skipping essay 42 with length 861...\n",
      "Skipping essay 45 with length 576...\n",
      "Skipping essay 49 with length 595...\n",
      "Processing batch 50/200\n",
      "Skipping essay 55 with length 570...\n",
      "Skipping essay 57 with length 626...\n",
      "Processing batch 60/200\n",
      "Skipping essay 66 with length 776...\n",
      "Processing batch 70/200\n",
      "Skipping essay 71 with length 669...\n",
      "Skipping essay 75 with length 539...\n",
      "Skipping essay 76 with length 627...\n",
      "Skipping essay 79 with length 611...\n",
      "Processing batch 80/200\n",
      "Skipping essay 83 with length 695...\n",
      "Skipping essay 87 with length 996...\n",
      "Skipping essay 89 with length 747...\n",
      "Processing batch 90/200\n",
      "Skipping essay 93 with length 525...\n",
      "Skipping essay 98 with length 777...\n",
      "Processing batch 100/200\n",
      "Skipping essay 105 with length 588...\n",
      "Skipping essay 109 with length 840...\n",
      "Processing batch 110/200\n",
      "Skipping essay 117 with length 810...\n",
      "Processing batch 120/200\n",
      "Skipping essay 121 with length 568...\n",
      "Skipping essay 125 with length 531...\n",
      "Skipping essay 126 with length 515...\n",
      "Processing batch 130/200\n",
      "Skipping essay 131 with length 637...\n",
      "Processing batch 140/200\n",
      "Skipping essay 141 with length 927...\n",
      "Skipping essay 145 with length 940...\n",
      "Skipping essay 150 with length 544...\n",
      "Skipping essay 151 with length 1098...\n",
      "Skipping essay 154 with length 689...\n",
      "Skipping essay 156 with length 670...\n",
      "Processing batch 160/200\n",
      "Skipping essay 165 with length 762...\n",
      "Processing batch 170/200\n",
      "Skipping essay 175 with length 740...\n",
      "Skipping essay 176 with length 1068...\n",
      "Processing batch 180/200\n",
      "Processing batch 190/200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.33      0.67      0.44         3\n",
      "           B       0.37      0.67      0.48        15\n",
      "           C       1.00      0.10      0.18        30\n",
      "           D       0.47      0.94      0.62        50\n",
      "           E       0.33      0.06      0.10        34\n",
      "           F       0.86      0.58      0.69        33\n",
      "\n",
      "    accuracy                           0.50       165\n",
      "   macro avg       0.56      0.50      0.42       165\n",
      "weighted avg       0.60      0.50      0.43       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "n=10 # print progress every nth batch\n",
    "y_test = []\n",
    "y_pred = []\n",
    "max_length = 512  # Maximum length for BERT-based models\n",
    "\n",
    "for index in range(len(essays_test)):\n",
    "    \n",
    "    essay = essays_test[index]\n",
    "    category_label = grades_test[index]  # This is the original encoded category label\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Assign a score to the following essay.\n",
    "    \n",
    "    {essay}\n",
    "    \n",
    "    Score:\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the essay and tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Check the length of the tokenized essay\n",
    "    input_length = inputs.input_ids.size(1)\n",
    "    if input_length > max_length:\n",
    "        print(f\"Skipping essay {index} with length {input_length}...\")\n",
    "        continue\n",
    "    \n",
    "    # Move tensors to the same device as the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make sure your models are in evaluation mode\n",
    "    original_model.eval()\n",
    "    peft_model.eval()\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "    # Get model predictions\n",
    "        peft_model_outputs = peft_model(**inputs)\n",
    "\n",
    "        # Extract the predicted class index from the outputs\n",
    "        peft_model_pred_index = torch.argmax(peft_model_outputs.logits, dim=-1)\n",
    "\n",
    "        # Convert predicted indices to class labels using the label encoder\n",
    "        # Ensure that the output is reshaped to 1D if necessary.\n",
    "        peft_model_label = label_encoder.inverse_transform(peft_model_pred_index.cpu().numpy().reshape(-1))[0]\n",
    "        \n",
    "        # Populate y_test and y_pred\n",
    "        category_label_true=label_encoder.inverse_transform([category_label])[0]\n",
    "        y_test.append(category_label_true.item()) \n",
    "        y_pred.append(peft_model_label)  \n",
    "        \n",
    "        # Print progress message every nth iteration\n",
    "        if index % n == 0:\n",
    "            print(f\"Processing batch {index}/{len(essays_test)}\")    \n",
    "\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc81d8-2f4e-470a-8873-c2806c10ad78",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8da563de-3f99-49d7-af7f-37eda1a3bcf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"], yticklabels=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5400f1-1045-434a-b568-fce242cd0457",
   "metadata": {},
   "source": [
    "#### Save y_test and y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2dded424-2713-424c-99f0-0250d73723f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_test_y_pred.csv'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Combine y_test and y_pred into a single list of tuples for easier CSV writing\n",
    "combined_data = list(zip(y_test, y_pred))\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'y_test_y_pred.csv'\n",
    "\n",
    "# Writing to csv file\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Optionally write header\n",
    "    writer.writerow(['y_test', 'y_pred'])\n",
    "    writer.writerows(combined_data)\n",
    "\n",
    "# Return the path for download\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46c2b3-9bf4-4a84-b704-4dd62cd8df33",
   "metadata": {},
   "source": [
    "#### Combine classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ac61ad0-42bb-4ea2-b22b-778aab15d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AB       0.48      0.89      0.63        18\n",
      "          CD       0.62      0.81      0.71        80\n",
      "          EF       0.96      0.40      0.57        67\n",
      "\n",
      "    accuracy                           0.65       165\n",
      "   macro avg       0.69      0.70      0.63       165\n",
      "weighted avg       0.75      0.65      0.64       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to map old classes to new classes\n",
    "def map_to_new_class(old_class):\n",
    "    if old_class in ['A', 'B']:\n",
    "        return 'AB'\n",
    "    elif old_class in ['C', 'D']:\n",
    "        return 'CD'\n",
    "    elif old_class in ['E', 'F']:\n",
    "        return 'EF'\n",
    "\n",
    "# Map the original classes to the new classes\n",
    "new_true_labels = [map_to_new_class(label) for label in y_test]\n",
    "new_predictions = [map_to_new_class(label) for label in y_pred]\n",
    "    \n",
    "# Calculate the new classification report\n",
    "new_report = classification_report(new_true_labels, new_predictions)\n",
    "print(new_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8305a-cb80-436a-92b1-27f3cdb19b0a",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5a98c62-6b20-467f-a87f-8b8cbdee3bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(new_true_labels, new_predictions, labels=[\"AB\", \"CD\", \"EF\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[\"AB\", \"CD\", \"EF\"], yticklabels=[\"AB\",\"CD\",\"EF\"])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b0b51-6138-48a7-92cb-6d9d5c8c94d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
