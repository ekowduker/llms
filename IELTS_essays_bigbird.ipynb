{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90745289",
   "metadata": {},
   "source": [
    "# IELTS Scored Essays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01798107",
   "metadata": {},
   "source": [
    "In this notebook I fine-tune a language model and use it to score a selection of IELTS essays.  \n",
    "IELTS is a is a widely recognized international language proficiency test used to assess language skills and proficiency for academic and general purposes.  \n",
    "[More information on the dataset can be found on Kaggle.](https://www.kaggle.com/datasets/mazlumi/ielts-writing-scored-essays-dataset/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c0dd6-4038-4cf6-adcc-1970a15c3bf2",
   "metadata": {},
   "source": [
    "The model  \n",
    "BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle.\n",
    "4,096 tokens equates to approximately 11 pages of text, given standard document formatting and average word lengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286b90",
   "metadata": {},
   "source": [
    "### Install and load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b0cc67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: protobuf==3.20 in /opt/conda/lib/python3.10/site-packages (3.20.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    loralib==0.1.1 --quiet\n",
    "\n",
    "%pip install matplotlib --quiet\n",
    "\n",
    "!pip install sentencepiece\n",
    "\n",
    "!pip install protobuf==3.20 # Downgrade the protobuf package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126d8fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, BigBirdForSequenceClassification, BigBirdConfig, AdamW\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fc2b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8fa80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ielts_writing_dataset.csv\")\n",
    "print(f\"There are {len(df)} essays in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba1a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.count()\n",
    "# The intermediate columns have no entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a4890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the columns you don't need\n",
    "columns_to_drop = ['Task_Type',\n",
    "                   'Examiner_Commen',\n",
    "                  'Task_Response',\n",
    "                  'Coherence_Cohesion',\n",
    "                 'Lexical_Resource',\n",
    "                 'Range_Accuracy']\n",
    "\n",
    "df.drop(columns_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3810a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed761ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the Question and Essay columns\n",
    "df['Combined'] = 'Question: ' + df['Question'] + '\\n\\n' + 'Essay: ' + df['Essay']\n",
    "\n",
    "# Delete the original Question and Essay columns\n",
    "df.drop(['Question', 'Essay'], axis=1, inplace=True)\n",
    "\n",
    "# Swap the position of the Combined and Overall columns\n",
    "df = df[['Combined','Overall', ]]\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4e448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check one example\n",
    "print(df[\"Combined\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa46db",
   "metadata": {},
   "source": [
    "#### Save the df as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd39add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('ielt_essays.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919df1aa",
   "metadata": {},
   "source": [
    "### Define a DataSet Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9b737",
   "metadata": {},
   "source": [
    "This code defines a PyTorch Dataset class for a dataset of essays and their grades. The class has two constructor arguments, `essays` and `grades`, which are lists of the essays and grades, respectively. The class also has a tokenizer, which is an instance of the `BertTokenizer` class from the `transformers` library.\n",
    "\n",
    "The `__len__` method of the class returns the length of the dataset.  \n",
    "The `__getitem__` method takes an index as an argument and returns a dictionary of tokenized tokens and a tensor of the grade for the essay at that index. The tokenization is done using the `BertTokenizer` class, with truncation and padding to a maximum length of 512 tokens.\n",
    "\n",
    "Here is a more detailed explanation of the code:\n",
    "\n",
    "* The `__init__` method first initializes the `essays` and `grades` attributes to the values passed to the constructor. It then initializes the `tokenizer` attribute to an instance of the `BertTokenizer` class, passing the `model_name` argument to the constructor.\n",
    "* The `__len__` method simply returns the length of the `essays` list.\n",
    "* The `__getitem__` method first gets the essay and grade at the specified index from the `essays` and `grades` lists, respectively. It then uses the `tokenizer` to tokenize the essay, with truncation and padding to a maximum length of 512 tokens. The tokenized tokens are returned in a dictionary, with the keys being the token names and the values being the token indices. The grade for the essay is also returned as a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e52313-7012-45f8-a53a-44512710a6d9",
   "metadata": {},
   "source": [
    "The max_length-token limit is based on constraints related to memory and computational resources. Processing longer sequences requires exponentially more memory and computational power due to the nature of self-attention mechanisms in these models. As such, a limit is set to ensure the model can be trained and used effectively on available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89921f55-a704-42f6-b998-5e1b0591d57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'google/bigbird-roberta-base'\n",
    "\n",
    "class EssayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, essays, grades):\n",
    "        self.essays = essays\n",
    "        self.grades = grades\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.essays)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        essay = self.essays[idx]\n",
    "        grade = self.grades[idx]\n",
    "        tokens = self.tokenizer(essay, truncation=True, padding='max_length', max_length=1024)\n",
    "        return {key: torch.tensor(val, dtype=torch.long) for key, val in tokens.items()}, torch.tensor(grade, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e9097",
   "metadata": {},
   "source": [
    "#### Load the data as a huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccbf6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-60a3f8ef85fec4c6/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3224e8c7eadf46c99235bfe355555b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'Combined', 'Overall'],\n",
      "        num_rows: 1435\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files='ielt_essays.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09f87",
   "metadata": {},
   "source": [
    "#### Extract the essays and the grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc4236fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essays = dataset['train']['Combined'] # list of essay strings\n",
    "grades = dataset['train']['Overall'] # list of numerical grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb3c19",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d8d4115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and temporary sets (80/20 split)\n",
    "essays_train, essays_temp, grades_train, grades_temp = train_test_split(\n",
    "    essays, grades, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets (50/50 split)\n",
    "essays_val, essays_test, grades_val, grades_test = train_test_split(\n",
    "    essays_temp, grades_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86889b35",
   "metadata": {},
   "source": [
    "#### Scale the grades  \n",
    "QuantileTransformer: This scaler transforms the features to follow a uniform or a normal distribution.  \n",
    "Therefore, for a given feature, this transformation tends to spread out the most frequent values and reduces the impact of (marginal) outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "342d4853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (143). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (144). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Convert grades_train, grades_val, and grades_test lists to numpy arrays\n",
    "grades_train = np.array(grades_train).reshape(-1,1)\n",
    "grades_val = np.array(grades_val).reshape(-1,1)\n",
    "grades_test = np.array(grades_test).reshape(-1,1)\n",
    "\n",
    "# Apply the Quantile Transformer\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal')\n",
    "grades_train_scaled = quantile_transformer.fit_transform(grades_train)\n",
    "grades_val_scaled = quantile_transformer.fit_transform(grades_val)\n",
    "grades_test_scaled = quantile_transformer.fit_transform(grades_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b6a47",
   "metadata": {},
   "source": [
    "#### Tokenize the data  \n",
    "Create a dataset where each item is a tuple containing the tokenized essay and the corresponding numerical grade.  \n",
    "These datasets can then be used to create DataLoaders which will handle batching of data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4854b8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = EssayDataset(essays_train, grades_train_scaled)\n",
    "val_dataset = EssayDataset(essays_val, grades_val_scaled)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccde5a",
   "metadata": {},
   "source": [
    "#### Initialize the original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84fe7b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "original_model = BigBirdForSequenceClassification.from_pretrained(model_name, num_labels=1)  # For regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e4687",
   "metadata": {},
   "source": [
    "#### Print the number of trainable model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e91a347a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 128060161\n",
      "all model parameters: 128060161\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971a09f",
   "metadata": {},
   "source": [
    "### Parameter efficient fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054771e2",
   "metadata": {},
   "source": [
    "#### 6.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
    "\n",
    "Performing full-finetuning can lead to catastrophic forgetting because it changes all parameters on the model. Since PEFT only updates a small subset of parameters, it's more robust against this catastrophic forgetting effect.\n",
    "\n",
    "Set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2af51b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft==0.3.0 --quiet\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.self.query\", \"attention.self.value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS # Sequence classificatio task\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6605",
   "metadata": {},
   "source": [
    "#### Add LoRA adapter layers/parameters to the original LLM to be trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7450977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 2362370\n",
      "all model parameters: 129831170\n",
      "percentage of trainable model parameters: 1.82%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model, lora_config)\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e3613",
   "metadata": {},
   "source": [
    "#### 6.3 - Train PEFT Adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1891892-b516-47f5-8fe1-b1399c68c387",
   "metadata": {},
   "source": [
    "This code is for fine-tuning a PEFT model on the IELTs essay dataset. It uses a learning rate of 1e-3 and a ReduceLROnPlateau scheduler with a patience of 3. The training and validation loops are implemented using the `process_batch()` function, which handles RuntimeErrors that occur when the TPU is out of memory. The model is saved to disk if the validation loss improves, and early stopping is implemented if the validation loss does not improve for 8 epochs.\n",
    "\n",
    "Here is a detailed explanation of the code:\n",
    "\n",
    "* The `n_epochs` variable specifies the number of epochs to train for.\n",
    "* The `patience` variable specifies the number of epochs to wait after the last time the validation loss improved before early stopping is triggered.\n",
    "* The `patience_counter` variable is used to track the number of epochs since the last time the validation loss improved.\n",
    "* The `best_val_loss` variable stores the lowest validation loss that has been achieved so far.\n",
    "* The `best_model` variable stores the weights of the model that achieved the best validation loss.\n",
    "* The `optimizer` variable is an instance of the AdamW optimizer, which is used to optimize the PEFT model's parameters.\n",
    "* The `scheduler` variable is an instance of the ReduceLROnPlateau scheduler, which is used to reduce the learning rate if the validation loss does not improve for a specified number of epochs.\n",
    "* The `peft_model_path` variable specifies the path to the directory where the PEFT model and tokenizer will be saved.\n",
    "* The `process_batch()` function handles RuntimeErrors that occur when the TPU is out of memory. It takes a batch of data, a PEFT model, and a boolean flag indicating whether the model is in training mode as input. If the model is in training mode, the gradients are zeroed and the loss is calculated. The loss is then backpropagated and the optimizer is used to update the model's parameters. If the model is not in training mode, the logits are calculated and returned.\n",
    "* The `train_loss` variable is used to store the total loss for the training epoch.\n",
    "* The `val_preds` and `val_labels` variables are used to store the predictions and labels for the validation set.\n",
    "* The `val_mse` variable is used to store the mean squared error between the predictions and labels for the validation set.\n",
    "* The `scheduler.step()` function is used to reduce the learning rate if the validation loss does not improve.\n",
    "* The `patience_counter` variable is incremented if the validation loss does not improve.\n",
    "* The `early stopping check` is triggered if the validation loss does not improve for 8 epochs. The training loop is then terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e34c9-88b3-427c-98fc-b17339db20cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss: 1.0372480524496899\n",
      "Validation MSE: 2.289461273497354\n",
      "Validation MSE improved to 2.289461273497354. Saving model!\n",
      "Epoch 2, Training loss: 1.4541958248656657\n",
      "Validation MSE: 0.9449602398515122\n",
      "Validation MSE improved to 0.9449602398515122. Saving model!\n",
      "Epoch 3, Training loss: 0.9987528264626033\n",
      "Validation MSE: 1.1764783283873508\n",
      "Validation MSE did not improve. Patience: 1/5\n",
      "Epoch 4, Training loss: 0.7624725503329601\n",
      "Validation MSE: 1.1107129676351983\n",
      "Validation MSE did not improve. Patience: 2/5\n",
      "Epoch 6, Training loss: 0.720506975116829\n",
      "Validation MSE: 0.9837131440700191\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation MSE did not improve. Patience: 4/5\n",
      "Epoch 8, Training loss: 0.3830901011048506\n",
      "Validation MSE: 0.7779729928738243\n",
      "Validation MSE improved to 0.7779729928738243. Saving model!\n",
      "Epoch 9, Training loss: 0.3386776602516572\n",
      "Validation MSE: 0.7075429963527182\n",
      "Validation MSE improved to 0.7075429963527182. Saving model!\n",
      "Epoch 10, Training loss: 0.3297597495839\n",
      "Validation MSE: 0.7577467208758888\n",
      "Validation MSE did not improve. Patience: 1/5\n",
      "Epoch 11, Training loss: 0.2917189065418724\n",
      "Validation MSE: 0.6649533368254544\n",
      "Validation MSE improved to 0.6649533368254544. Saving model!\n",
      "Epoch 12, Training loss: 0.2658794352836493\n",
      "Validation MSE: 0.6174720820270518\n",
      "Validation MSE improved to 0.6174720820270518. Saving model!\n",
      "Epoch 13, Training loss: 0.24173654282155135\n",
      "Validation MSE: 0.6029157739012607\n",
      "Validation MSE improved to 0.6029157739012607. Saving model!\n",
      "Epoch 14, Training loss: 0.220027335272688\n",
      "Validation MSE: 0.6903511789488112\n",
      "Validation MSE did not improve. Patience: 1/5\n",
      "Epoch 17, Training loss: 0.16874696342791948\n",
      "Validation MSE: 0.6065937716003909\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation MSE did not improve. Patience: 4/5\n",
      "Epoch 18, Training loss: 0.1430465320008807\n",
      "Validation MSE: 0.6060546290711303\n",
      "Validation MSE did not improve. Patience: 5/5\n",
      "Stopping early after 5 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "# With retry and learning rate scheduler\n",
    "\n",
    "import time\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "n_epochs = 20  # Make this a high number to benefit from early stopping\n",
    "patience = 5  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0  # Counter for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr=1e-3)  # Use a higher learning rate than full fine tuning\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "peft_model_path =  './peft-essay-ielts-bigbird'\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n",
    "def process_batch(batch, model, is_training):\n",
    "    \"\"\"\n",
    "    Retry decorator to handle RuntimeErrors that occur when the TPU is out of memory.\n",
    "\n",
    "    Args:\n",
    "        batch (tuple): A tuple containing the input tensors and labels for a single batch.\n",
    "        model (torch.nn.Module): The PEFT model.\n",
    "        is_training (bool): Whether the model is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        loss (float): The loss for the batch.\n",
    "        logits (list): The logits for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # If training, set the model to training mode and zero the gradients.\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    # Unpack and process the batch\n",
    "    tokenized_tensors = batch[0]\n",
    "    grades = batch[1]\n",
    "\n",
    "    input_ids = tokenized_tensors['input_ids']\n",
    "    attention_mask = tokenized_tensors['attention_mask']\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.set_grad_enabled(is_training):\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=grades if is_training else None)\n",
    "\n",
    "    # If training, calculate the loss and perform backpropagation.\n",
    "    if is_training:\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item(), None\n",
    "    else:\n",
    "        return None, outputs.logits.squeeze().tolist()\n",
    "    \n",
    "start_time = time.time()  # Start time\n",
    "\n",
    "# Training and Validation Loops\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    # Training loop\n",
    "    for batch in train_dataloader:\n",
    "        loss, _ = process_batch(batch, peft_model, True)\n",
    "        train_loss += loss\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Training loss: {train_loss / len(train_dataloader)}')\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            _, logits = process_batch(batch, peft_model, False)\n",
    "            val_preds.extend(logits)\n",
    "            val_labels.extend(batch[1].tolist())\n",
    "\n",
    "    val_mse = mean_squared_error(val_labels, val_preds)\n",
    "    print(f'Validation MSE: {val_mse}')\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(val_mse)\n",
    "\n",
    "    # Check if validation loss improved\n",
    "    if val_mse < best_val_loss:\n",
    "        best_val_loss = val_mse\n",
    "        best_model = copy.deepcopy(peft_model.state_dict())\n",
    "        patience_counter = 0\n",
    "        print(f'Validation MSE improved to {val_mse}. Saving model!')\n",
    "        \n",
    "        # Save best model to disk\n",
    "        # First ensure the best model weights are loaded\n",
    "        peft_model.load_state_dict(best_model)\n",
    "\n",
    "        # Save model weights\n",
    "        peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "        # Save tokenizer from the train_dataset\n",
    "        train_dataset.tokenizer.save_pretrained(peft_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation MSE did not improve. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Stopping early after {patience_counter} epochs without improvement.')\n",
    "        break\n",
    "\n",
    "end_time = time.time()  # End time\n",
    "total_time = end_time - start_time  # Total training time in seconds\n",
    "\n",
    "print(f\"Total training time: {total_time // 60:.0f} minutes {total_time % 60:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe4fe1",
   "metadata": {},
   "source": [
    "#### Save the final best model and the corresponding tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0d0a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-essay-ielts-bigbird/tokenizer_config.json',\n",
       " './peft-essay-ielts-bigbird/special_tokens_map.json',\n",
       " './peft-essay-ielts-bigbird/spiece.model',\n",
       " './peft-essay-ielts-bigbird/added_tokens.json',\n",
       " './peft-essay-ielts-bigbird/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the best model weights are loaded\n",
    "peft_model.load_state_dict(best_model)\n",
    "\n",
    "# Save model weights\n",
    "peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "# Save tokenizer from the train_dataset\n",
    "train_dataset.tokenizer.save_pretrained(peft_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f987d-83e2-4d50-84c3-03737046a91f",
   "metadata": {},
   "source": [
    "#### Optional: Reload model and tokenizer from file when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79c443-1009-47e1-93cf-bbaf8e89cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = BigBirdForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55167212",
   "metadata": {},
   "source": [
    "### Inference\n",
    "#### Prepare this model by adding an adapter to the original model.\n",
    "Set is_trainable=False because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set is_trainable=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e38f8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = BigBirdForSequenceClassification.from_pretrained(model_name, num_labels=1, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       peft_model_path, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       num_labels=1,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c5cb3",
   "metadata": {},
   "source": [
    "#### Evaluate the performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb75f5",
   "metadata": {},
   "source": [
    "The code is used to evaluate the performance of a BERT-based model for essay scoring. The model is first trained on a dataset of essays and their corresponding grades. Then, the model is tested on a separate dataset of essays and their grades. The metrics used to evaluate the model's performance are mean squared error (MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).\n",
    "\n",
    "The code starts by importing the necessary libraries, including numpy, sklearn, and torch. It then defines a function to calculate mean absolute percentage error (MAPE).\n",
    "\n",
    "The next step is to load the data. The data is stored in two lists: essays_test and grades_test. The essays_test list contains the essays that will be used to test the model, and the grades_test list contains the corresponding grades for each essay.\n",
    "\n",
    "The code then loops through the essays_test list, one essay at a time. For each essay, the code creates a prompt that includes the essay text and a request for a score. The prompt is then passed to the tokenizer, which converts it into a sequence of tokens. The tokens are then passed to the model, which makes a prediction for the essay's grade. The prediction is then appended to the y_pred list.\n",
    "\n",
    "The code also checks the length of the tokenized essay. If the length of the essay is greater than the maximum length allowed by the model, the code skips the essay and moves on to the next one.\n",
    "\n",
    "Once all of the essays have been processed, the code calculates the MSE, MAE, and MAPE scores. The scores are then printed to the console.\n",
    "\n",
    "Here is a more detailed explanation of the code:\n",
    "\n",
    "* The `import` statements import the necessary libraries for the code to run.\n",
    "* The `def mean_absolute_percentage_error()` function calculates MAPE.\n",
    "* The `load_data()` function loads the data from the `essays_test` and `grades_test` lists.\n",
    "* The `for` loop iterates through the essays_test list, one essay at a time.\n",
    "* The `prompt` variable is created by concatenating the essay text and a request for a score.\n",
    "* The `inputs` variable is created by passing the prompt to the tokenizer.\n",
    "* The `input_length` variable is calculated by getting the size of the first dimension of the `inputs.input_ids` tensor.\n",
    "* If the `input_length` is greater than the maximum length allowed by the model, the code skips the essay and moves on to the next one.\n",
    "* The `device` variable is set to `cuda` if CUDA is available, otherwise it is set to `cpu`.\n",
    "* The `inputs` variable is updated by moving the tensors to the same device as the model.\n",
    "* The `original_model` and `peft_model` are set to evaluation mode.\n",
    "* The `torch.no_grad()` context manager is used to disable gradient calculation for inference.\n",
    "* The `peft_model_outputs` variable is created by passing the `inputs` to the `peft_model`.\n",
    "* The `peft_model_score` variable is created by getting the value of the `logits` tensor from the `peft_model_outputs` variable.\n",
    "* The `y_pred` list is updated by appending the `peft_model_score` value.\n",
    "* The `y_test` list is updated by appending the corresponding grade value from the `grades_test` list.\n",
    "* The `if` statement prints a progress message every nth iteration.\n",
    "* The `y_pred_original` and `y_test_original` variables are created by scaling the grades back to their original values.\n",
    "* The `mse`, `mae`, and `mape` variables are calculated by using the `mean_squared_error()`, `mean_absolute_error()`, and `mean_absolute_percentage_error()` functions.\n",
    "* The `print()` statements print the MSE, MAE, and MAPE scores to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f80ce1-5009-4af0-98e8-a86928077915",
   "metadata": {},
   "source": [
    "MAPE\n",
    "For regression tasks, the concept of an error percentage is not as straightforward as in classification tasks because the range of possible values is not bounded between 0 and 1. However, there are relative error metrics that can provide a sense of the error relative to the magnitude of the values being predicted. One such metric is the Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "MAPE measures the size of the error in percentage terms. It is calculated as the average of the absolute percentage errors of the predictions.\n",
    "\n",
    "MAPE has some drawbacks, though:\n",
    "\n",
    "It can be undefined if any y true values are or close to zero.\n",
    "It puts a heavier penalty on negative errors than positive ones in certain contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff814f46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0/144\n",
      "Processing batch 10/144\n",
      "Processing batch 20/144\n",
      "Processing batch 30/144\n",
      "Processing batch 40/144\n",
      "Processing batch 50/144\n",
      "Processing batch 60/144\n",
      "Processing batch 70/144\n",
      "Processing batch 80/144\n",
      "Processing batch 90/144\n",
      "Processing batch 100/144\n",
      "Processing batch 110/144\n",
      "Processing batch 120/144\n",
      "Processing batch 130/144\n",
      "Processing batch 140/144\n",
      "\n",
      "\n",
      "Mean Squared Error: 0.60\n",
      "Mean Absolute Error: 0.57\n",
      "Mean Absolute Percentage Error (MAPE): 9.26%\n",
      "Total inference time: 0 minutes 28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set scores\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "n=10 # print progress every nth batch\n",
    "y_test = []\n",
    "y_pred = []\n",
    "max_length = 4096  # Maximum length for BigBird model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for index in range(len(essays_test)):\n",
    "    \n",
    "    essay = essays_test[index]\n",
    "    scaled_score = grades_test_scaled[index]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Assign a score to the following essay.\n",
    "    \n",
    "    {essay}\n",
    "    \n",
    "    Score:\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Check the length of the tokenized essay\n",
    "    input_length = inputs.input_ids.size(1)\n",
    "    if input_length > max_length:\n",
    "        print(f\"Skipping essay {index} with length {input_length}...\")\n",
    "        continue\n",
    "    \n",
    "    # Move tensors to the same device as the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make sure your models are in evaluation mode\n",
    "    original_model.eval()\n",
    "    peft_model.eval()\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions\n",
    "        peft_model_outputs = peft_model(**inputs)\n",
    "        peft_model_score = peft_model_outputs.logits.squeeze().item()\n",
    "\n",
    "        y_pred.append(peft_model_score)\n",
    "        y_test.append(scaled_score)\n",
    "    \n",
    "    # Print progress message every nth iteration\n",
    "    if index % n == 0:\n",
    "        print(f\"Processing batch {index}/{len(essays_test)}\")    \n",
    "        \n",
    "# Scale the grades back to their original values\n",
    "y_pred_original = quantile_transformer.inverse_transform(np.array(y_pred).reshape(-1,1))\n",
    "y_test_original = quantile_transformer.inverse_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "# Calculate MSE, MAE, MAPE\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "end_time = time.time()  # End time\n",
    "total_time = end_time - start_time  # Total training time in seconds\n",
    "\n",
    "print(f\"Total inference time: {total_time // 60:.0f} minutes {total_time % 60:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8f3f6",
   "metadata": {},
   "source": [
    "#### Plot results  - with outlier identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174784a2-2b37-4d6f-81c0-ae2aa72b5625",
   "metadata": {},
   "source": [
    "For outliers to be identified and plotted (in red), you first need to define what qualifies as an outlier in your data.  \n",
    "A common approach is to use a threshold based on some metric, like the absolute difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a55a5110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Outliers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example threshold for outliers\n",
    "outlier_threshold = 1.25  # Absolute allowable difference between actual and poredicted values\n",
    "\n",
    "# Plot each point, coloring outliers in red\n",
    "for actual, predicted in zip(y_test_original, y_pred_original):\n",
    "    color = 'red' if abs(actual - predicted) > outlier_threshold else 'blue'\n",
    "    plt.scatter(actual, predicted, color=color)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "# Plot the reference line\n",
    "plt.plot([min(y_test_original), max(y_test_original)], [min(y_test_original), max(y_test_original)], color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240b811-ed0c-4c7f-a8d0-1427b4447894",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate the tolerance distribution of the scores.  \n",
    "i.e. how many essays fall within a certtain tolerance of the actual score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2dbcdc1-cc04-45e3-ae7a-e515aefa23cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance Level | Number of Essays | % of Total Essays | Cumulative %\n",
      "-------------------------------------------------------------------------\n",
      "            5% |               43 |                30% |            30%\n",
      "           10% |               59 |                41% |            71%\n",
      "           15% |                8 |                 6% |            76%\n",
      "           20% |               22 |                15% |            92%\n",
      "          25%+ |                9 |                 6% |            98%\n"
     ]
    }
   ],
   "source": [
    "total_essays = len(y_test_original)\n",
    "tolerance_counts = {\"5%\": 0, \"10%\": 0, \"15%\": 0, \"20%\": 0, \"25%+\": 0}\n",
    "\n",
    "for actual, predicted in zip(y_test_original, y_pred_original):\n",
    "    percent_error = abs(actual - predicted) / actual\n",
    "\n",
    "    if percent_error <= 0.05:\n",
    "        tolerance_counts[\"5%\"] += 1\n",
    "    elif percent_error <= 0.10:\n",
    "        tolerance_counts[\"10%\"] += 1\n",
    "    elif percent_error <= 0.15:\n",
    "        tolerance_counts[\"15%\"] += 1\n",
    "    elif percent_error <= 0.20:\n",
    "        tolerance_counts[\"20%\"] += 1\n",
    "    elif percent_error > 0.25:\n",
    "        tolerance_counts[\"25%+\"] += 1\n",
    "\n",
    "# Calculate cumulative percentage\n",
    "cumulative_count = 0\n",
    "print(\"Tolerance Level | Number of Essays | % of Total Essays | Cumulative %\")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "for tolerance, count in tolerance_counts.items():\n",
    "    cumulative_count += count\n",
    "    cumulative_percentage = (cumulative_count / total_essays) * 100\n",
    "    percentage = (count / total_essays) * 100\n",
    "    print(f\"{tolerance:>14} | {count:>16} | {percentage:>17.0f}% | {cumulative_percentage:>13.0f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b8c47-b0c9-4276-b456-de11f02bebcf",
   "metadata": {},
   "source": [
    "#### Pull out the outliers for human evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79916518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 outliers out of 144 essays.\n",
      "Here are the 14 outlier essays. You may want to evaluate these yourself.\n",
      "\n",
      "OUTLIER ESSAYS\n",
      "[\n",
      "    {\n",
      "        \"essay\": \"Question: The bar chart below shows the number of houses built per year in two cities, Derby and Nottingham, Between 2000 and 2009. Write a report for a university lecturer describing the information shown below.You should write at least 150 words.\\n\\nEssay: The bar chart gives information regarding the number of houses annually built in two cities, Derby and Nottingham, between 2000 to 2009. Overall, more houses have been constructed in Derby during the given time.\\nIn 2000 and 2001, around 50 houses have been created in Nottingham. After, the number of new buildings decreased massively to less than 20. From 2003 to 2005, around 50 or more houses have been built. Later, the civil construction sector experienced a massive decline to less than 10 by 2006, before jumping to over 150. In 2008 the next dramatically fall happened again, and by 2009 around 250 new house have been created in that city.\\nOn the other hand, the construction of houses in Derby showed a much more moderate trend. It started by less than 50 new buildings during the first two years, before increasing to over 50 by 2002. From 2003 to 2007 Derby the construction of houses in Derby remained stable, without any major jumps. In 2008 and 2009, this city experienced a massive increase in new houses, namely between 250 and less 350.\",\n",
      "        \"actual_grade\": 7.0,\n",
      "        \"predicted_grade\": 8.7\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: Write about the following topic.To meet the growing need for food to support an increasing population, a country should make use of edible insects as a food source. However, some people believe that insects are not only unhealthy but harvesting them will also negatively affect nature. What are the benefits and drawbacks of eating insects?Give reasons for your answer and include any relevant examples from your own knowledge or experience.\\n\\nEssay: Nowadays, populations are growing all over the world, and increasing the source of food is becoming more important and also being challenging nowadays. One of the most important matters nowadays is eating insects and unhealthy sources of natural food. Some people in some areas are getting benefits from eating insects as a meal where insects are the worst scenario in nature.\\nhowever, there is some cultivating support that comes from insects which is a positive impact on the land or cultivating areas. Such as, it helps plants to grow fast and healthier. Many people use insects in their cultivating land as organic manure. it reduces dying trees and plants and provides enough energy and nutrition to plants to grow faster, healthier, and keep fresh. All over the world, people in so many areas are most familiar with those insects. By using insects on their land, they are doing it with less cost and more efficiency and also they are not providing too much effort to get insects as it comes from nature so easily.\\nFor some people, eating insects is so common and reliable but it gives a lot of bad experiences when it publishes negative reactions in the human body. some people suffer from eating insects a lot. sometimes it gives people nutrition and energy as they believe but sometimes it is just the worst scenario having or eating insects such as diarehuiya,colleriahuia, and common bacterial issues in the human body. Mostly it happens when people are not enough insured of using or knowing how to process insects and make them ready to eat.\",\n",
      "        \"actual_grade\": 4.5,\n",
      "        \"predicted_grade\": 7.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The bar chart below shows the numbers of men and women attending various evening courses at an adult education centre in the year 2009. The pie chart gives information about the ages of these course participants.Write a report for a university, lecturer describing the information shown below.\\n\\nEssay: These bar graph and pie chart illustrates the amounts of people in both genders extending the various classes of adult education in 2009. As the bar chart shows the differences of genders of male and female deligates. And the bar charts told the porpotion of each age group of people who joined the evening classes of this year.\\nOverview, there are almost a half of participants are over 50 years old, while the one fourth of it are milddle aged group. However, the less portion of the generation is under 20 years. as the bar graph give the number of women that were interested in language classes and men similarly attended painting as 25 % and sculture classes and Drama classes were attended by 10 % of men.\\nForm the pie chart, there are 43 % of 50 year old age group were able to join evening classes, oppositely , only 5 % of people who are under 20 decided to attend the night classes. 16 % of young adults attended the classes in 2019.\\nAs the bar graph illustrates that the women attended the classs more than men. The similar number of both genders are painting , they kept in the similar level. While, the large differences can be found in language course. The most unpopular clasess in either men or women are in sculpture learning.\",\n",
      "        \"actual_grade\": 4.5,\n",
      "        \"predicted_grade\": 6.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The pie charts below show how dangerous waste products are dealt with in three countries.Write a report for a university, lecturer describing the information shown below.\\n\\nEssay: The bar charts illustrate five different methods of how the Republic of Korea, Sweden, and the UK deal with waste products. The five methods are recycling, underground, incineration, chemical treatment, and dumping at sea.\\noverall, recycling is way more in Korea while underground dumping took first place in both Sweden and the UK.\\nFirst, Morethan two third of the waste is recycled in Korea while incineration is more than half in Sweden. Korea dumps 22% under the ground and incinerated less than 10%. Sweden, on the other hand, recycled a quarter of its waste but incinerated a fifth of the garbage.\\nSecond, the UK dumps most of its waste under the ground incinerating only 2%. Chemical treatment and dumping at sea both share 8% of the UK's waste product.\",\n",
      "        \"actual_grade\": 5.5,\n",
      "        \"predicted_grade\": 7.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: In some countries people spend long hours at work. Why does this happen? Is it positive or negative development\\n\\nEssay: Striving for own career development is most of the people's lifetime target in the modern city. In some nations, employees spend long time at work becomes a phenomenon. This essay is going yo discuss the reasons behind and I reckon that this is a negative development for both the companies and employees.\\nThere are two main reasons behind this phenomenon. Firstly, it could be the corporate culture of the company. The management members of the company may agree that workers spending a long period of time in the office equals to excellent performance. For instance, employees in Japanese company could get a greater annual bonus or better chance to promote if they are eager to work for a long hours. This forces the employees to to show up in the office just because of giving a good impression to the boss.\\nSecondly, as the competition between different companies in the market is nervous, coporate sectors are willing to push their colleagues to enhance their sales or performance. It causes a great pressure to the employees whom need to work for long hours to fuifill the expectation from the managements. For example, product sales agents' performance depends on the sales number quarterly. If the agent cannot sale the products effectively, they will receive less revenues or even being sacked.\\nAs per the reasons stated, I absolutely think that it is a negative development for both the employees and companies. It is because it gives the unnecessary pressure to the colleagues which will affect their mental health. Inversely, it downgrades the performance of the employee as well as the company. Work-life balance is important to everyone as suitable relaxing time can considerably enhance the performance of human.\",\n",
      "        \"actual_grade\": 7.5,\n",
      "        \"predicted_grade\": 6.2\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The diagram below shows how ethanol fuel is produced from corn.Summarise the information by selecting and reporting the main features and make comparisons where relevant.\\n\\nEssay: During the COVID-19 pandemic, countless measures have been implemented to reduce transmission amongst citizens. The use of hand sanitizers has been one of them, but what is it made of? Ethanol is a common disinfecting agent found in cleaning products, which originates from corn. Here's a nine-step manufacturing method of how this alcohol is produced from that supercrop.\\nIn the first third of production, the maize is harvested, stored and ground up during milling. First, farmers collect ripened ears from fields, and then place them in bins and other containers. These are then crushed into a powder to increase the surface area, hence increasing the potential yield of ethanol created.\\nSteps four to six involve boiling, brewing and filtration. The powder produced in the milling process is mixed with water and boiling takes four hours. Once it is done, the mixtue is left to stand for 48 hours, allowing fermentation to occur, and unprocessed ethanol be created. After this two-day step, the mixture is filtered to separate the unpurified ethanol from the solid by-product.\\nLastly, the liquid raw product is distilled, packaged in various containers and shipped to retailers. Filtration is carried out for five hours to increase the purity of the ethanol. Afterwards, the final product is packaged and stored until it is transported to stores, where we can purchase it for our daily use and protection.\\nMany important people such as farmers, scientist and transporters assist in the manufacturing process of ethanol and we thank them for creating this essential product.\",\n",
      "        \"actual_grade\": 8.5,\n",
      "        \"predicted_grade\": 7.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The charts below compare the age structure of the populations of France and India in 1984.Write a report for a university, lecturer describing the information shown below.\\n\\nEssay: The charts demonstrate the sex distribution in a various of age groups between France and India in 1984.\\nBy and large, the males and females in the population of France almost balanced each other particularly in the age groups of 0-65 years old in 1984 with a symmetric sex composition. The age group 30-35 was revealed to be the highest percentages of population in France whereas the largest proportion of Indian population was in the age group 0-5 with a skewed sex ratio.\\nGoing into more details, in regard to age structure of population, India had a vast majority of population in younger groups, constituting for 49% of population in the age groups of 0-20 years old. In particular, the highest percentages of Indian population presented in the age group 0-5 with the males to felamles ratio around 7% to 6.5%. Indian aged 70 years old or more was shown a steep decline, reaching less than 2% of population with balanced sex distribution.\\nIn contrast, French people aged 10 - 40 years old made up the largest section in demographic structure, accounting for approximately 45% of population. The age group 30-35 reported as the highest proportion of population in France with around 4% of population in each gender. The males to females ratio in the age group 85 years old or more was represented to be the smallest of population in France, by 0.2% males to 1% females of population.\",\n",
      "        \"actual_grade\": 8.0,\n",
      "        \"predicted_grade\": 6.5\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The bar chart below shows the number of houses built per year in two cities, Derby and Nottingham, Between 2000 and 2009. Write a report for a university lecturer describing the information shown below.You should write at least 150 words.\\n\\nEssay: The bar chart depicts the number of houses constructed per year ni two cities between 2000 to 2009. Overall, it is clear that the number of houses built in Derby steadily increased, while there are huge variations in the number of houses in Nottingham like a seesaw.\\nInitially, the number of houses newly built started at less than 50 in Derby in 2000. Then the number of houses increased and exceeded 100 in 2003. The number of houses remained almost the same until 2007, but the number of houses suddenly skyrocketed to 250 in 2008. As a result, the number of houses had nearly 350 in 2009.\\nWhen it comes to Nottingham, the number of houses built was 50 in 2000. It increased more than 50 in 2001, but the number of houses abruptly dropped less than 20 in 2002. Then the number started to soar steadily and had apploximately 75 in 2005. Despite of increase in 2005, the number of houses built drastically plummeted, it is about 10 in 2006. In 2007, the number of houses dramatically flied up. Specifically, it was close to 200. Although the number of houses surged in 2007, the number went down again. It is similar to 2006 and it seems to be tiny larger than 2006. Finally, the number skyrocketed again in 2009, it reached a peak of 250 in 2009. This city's number of houses is unpredictable every year.\",\n",
      "        \"actual_grade\": 6.5,\n",
      "        \"predicted_grade\": 8.5\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: Some people think history has nothing or little to tell us, but others think that studying the past history can help us better understand the present. Discuss both views and give your opinion.\\n\\nEssay: There is no argument that history is something related to the past generation which has never been seen by the present generation. which let some people think that history has nothing to teach us or has limited information. While others believe that in order to identify history we have to study it to help us in our modern lives. In my opinion, in the past even if they reach wonderful experiments it could be difficult to reach to our era. However, nowadays we are capable of knowing about the old history via modern technology.\\nOn one hand, old people are limited by the population which let the people in the same place communicate through symbols to be aware of enemies. Towards generations, these symbols turned into history. As a result, people think that it is just a piece of art by the old people. In fact, some of these are from scientists and have been written as a symbol. Moreover, till now those shapes meant nothing to us or are just small pieces of information.\\nOn the other hand, these days the government take a step forward and is trying hard to clarify those stones and what it means, In addition, some historical centers have scientists studying the old tools in order to have an idea from studying that symbols. For instance, Tomes Addison one of his achievement was the discovery of the light lamp which we are used to living with it. Therefore, this exploration comes from studying old history. In other words, each generation is capable to help the following generation.\\nIn conclusion, history is an element that can not be ignored from any period, because it could have very critical information. Finally, I believe that technology helped us recently to study those strange tools. consequently, the government should pay more attention to covering the experiment's expenses.\",\n",
      "        \"actual_grade\": 4.5,\n",
      "        \"predicted_grade\": 6.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The diagrams below show the existing ground floor plan of a house and a proposed plan for some building work.Summarise the information by selecting and reporting the main features and make comparisons where relevant.\\n\\nEssay: There are several differences on two diagrams of existing floor plan and proposed changes of it. Meanwhile, evidently illustrated above, some rough main features of the house remain the same such as the kitchen, living room and overall shape of the entire house.\\nOne of the most obvious changes is a shift of stairs' location and their form. In the existing floor plan, stairs are rather narrow and attached to the left side of the living room's internal room, whereas, in proposed changes, stairs occupy most of the hall space in a bigger form.\\nBoth two internal doors, one to the kitchen and one to the living room, have moved next to the entrance to provide a route into the kitchen as the living room no longer has an internal wall.\\nOnce entered the kitchen, a new kitchen furniture can be seen at the far end of the kitchen which ultimately reduces the area of the space itself.\",\n",
      "        \"actual_grade\": 5.5,\n",
      "        \"predicted_grade\": 7.0\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: Nowadays, not enough students choose science subjects in university in many countries. What are the reasons for this problem? What are the effects on society?\\n\\nEssay: Recently, more and more students choose to study finance, management or other subjects instead of science in university around the world. There are many reasons contribute to this phenomenon and this would definetely impose negative influences on our society.\\nIn terms of the factors, the reason is mainly due to the job market. Firstly, we have to admit that the number of science job vacancies in the market is significantly lower than the other occupations, like the nurse, the accountant, the lawyer and so on. Besides this, the science is comparatively difficult than the other subjects. If you want to be a qualified scientist, you are more likely to spend more time on learning and researching, maybe three years more than the other subjects. So, very naturally, few people would like to take the risk of learning science.\\nHowever, science does play an extremely important role in our society. If not enough people study science, it may impede the development of the country. Science represents the future of our nation because it could help to improve the development of technology and then make new technologies into pratical products. A good example can be seen in the United States, which has experienced a huge development in science during the past decades and has created a lot of advanced products, such as the Microsoft and Artificial intelligence, which has bring great benefits to this country in return and make it become the most powerful nation in the world. In contrast, if very few people learning science, the nation may remain at a standstill and lose its competitiveness.\\nIn conclusion, although few people want to study science, the government should take efficient measures to encourage the public to study this subject to help our society improving continuously in the long future.\",\n",
      "        \"actual_grade\": 5.5,\n",
      "        \"predicted_grade\": 7.5\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: The world is experiencing a dramatic increase in population, which is causing problems not only for poor, undeveloped countries, but also for industrialized and developed nations. Describe some of the problems that overpopulation causes, and suggest at least one possible solution.\\n\\nEssay: You should write at least 250 words.You should spend about 40 minutes on this task.Nowadays, the population dramatically in most countries around the world. This is true for the developed and developing nations. Overpopulation a different number of problems. However, the government can these problems in many .There are several problems that the raising number of people in undeveloped countries causes. Firstly, it is very difficult to provide enough food for all people. Secondly, the government limits the number of children per family in school. In addition, in poorest countries usually have , and when the population increases, the number of . Finally, when too many people live on the land, the environment suffers.There are different problems that overpopulation causes in rich nations. Firstly, it is very difficult for governments to provide helpful public services in overcrowded cities. Moreover, there is generally a higher level of crimes being committed, such as drugs abuse, murders, thefts, . often cause by the high rates of unemployment.However, overpopulation problems in nations have two main which they are by governments. Firstly, the government must educate people about limiting the size of the family. For example, in China they have a policy called \\u201cone child policy\\u201d which limits the size of the family to one or two children, and this is beginning to have an effect on the world\\u2019s most crowded nation.To sum up, if the impulsive population increase continues, many more people will die of hunger in the poor countries. Also, in rich nations, the life in the cities will become more and more difficult.\",\n",
      "        \"actual_grade\": 6.0,\n",
      "        \"predicted_grade\": 8.8\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: Write about the following topic.To meet the growing need for food to support an increasing population, a country should make use of edible insects as a food source. However, some people believe that insects are not only unhealthy but harvesting them will also negatively affect nature. What are the benefits and drawbacks of eating insects?Give reasons for your answer and include any relevant examples from your own knowledge or experience.\\n\\nEssay: Some countries and culture already utilize insects as part of food source. As such, it can be relatively inexpensive to consume insects - which are often freely found in certain environments and do not take much skill to be collected, killed and consumed - as compared to the cost and manual labor involved in raising animal livestock, butchering, as well as preparing the meat for consumption. Similarly agriculture also involves consistent manual labor, and has costs associated with it, including for machinery and materials needed. However, people may be against the idea of consuming insects due to the novelty of it, and they may also feel disgust around it. As the prompt states, some may find it unhealthy. Harvesting insects on purpose will also require some physical and psychological work - but the benefit here is that it may be easier than harvesting large animals or cultivating crops.\\nI have never consumed an insect product - and my father has mentioned to me that had lived in such-and-such country, I would not be so scared of cockroaches - viewing them as a food source. He intended this to be an ironic comment, meant to comfor me somewhat due to my strong aversion to cockroaches. However, he may be correct! For individuals socialized in such a society, their aversion to roaches may be lower than mine. Hence, part of the issue here is socialization and accepting this new food norm, should it be novel to the individual and/or the country.\\nI have tried an octopus for the first time when I was around 20 years old - as I was curious about this dish called Takoyaki, and had heard good reviews of it. It was not unpleasant to eat the ocotpus, per se, but I likely will not go back to it. All in all, new experiences, including consumption of new types of food, may create strong aversion at first, but once dip your toes into it, so to speak, it may be tamer than the experience you were expecting - even if you never go back to eating it again.\",\n",
      "        \"actual_grade\": 6.0,\n",
      "        \"predicted_grade\": 7.5\n",
      "    },\n",
      "    {\n",
      "        \"essay\": \"Question: Write about the following topic.Many people use written language in a less formal and more relaxed way. Why? Does this development have advantages and disadvantages?Give reasons for your answer and include any relevant examples from your own knowledge or experience.\\n\\nEssay: It is noticeable that when we write something we try to use more informal language. Moreover the written text is more redundant, cohesive, calm and patient. From my point of view, it comes because we erase emotions from written text which we spread sometimes without intention via voice. Not only voice influence on it, but during the writing we have a chance to revise and check our text. Moreover this fact has advantages and disadvantages.\\nOn the one hand, there is a huge advantage of this cartain. When we communicate through formal language and when we are more relaxed we have a chance to spread our ideas more thoroughly. For instance, I sometimes observe that for me it is easier to convince someone to help me if I write to him or her.\\nOn the other hand, there is a disadvantage, that when we switch on to the speech from writing other people will be surprised or astonished with the differences. For example, during my work, I communicate via messages more than via calling. Sometimes there are cases when after this switching people notice that I was rude and insult them.\\nFinally, written language is more relaxed and less formal. This fact has a lot of cons and pros. I think that cons dominate under pros. What is more, it is a nice way to mix this kind of communication for best results. Neither written way nor speaking will increase your chance to be recognizable in the right way if your basic idea is not relevant to consumers of your main idea.\",\n",
      "        \"actual_grade\": 5.0,\n",
      "        \"predicted_grade\": 6.5\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "outliers = []\n",
    "\n",
    "for index, (actual, predicted) in enumerate(zip(y_test_original, y_pred_original)):\n",
    "    if abs(actual - predicted) > outlier_threshold:\n",
    "        outlier_info = {\n",
    "            'essay': essays_test[index],\n",
    "            'actual_grade': actual.item(),\n",
    "            'predicted_grade': round(predicted.item(),1)\n",
    "        }\n",
    "        outliers.append(outlier_info)\n",
    "\n",
    "# Convert outliers list to JSON format\n",
    "outliers_json = json.dumps(outliers, indent=4)\n",
    "print(f\"There are {len(outliers)} outliers out of {len(essays_test)} essays.\")\n",
    "print(f\"Here are the {len(outliers)} outlier essays. You may want to evaluate these yourself.\\n\")\n",
    "print(\"OUTLIER ESSAYS\")\n",
    "print(outliers_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871a845-d1eb-4c0c-8858-20f01f98525d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GPT4 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4215ad6-e017-4491-ada5-489ad55bb902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
