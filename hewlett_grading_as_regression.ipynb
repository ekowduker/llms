{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43d1926-71b7-4689-8547-84f7576f3c49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Grading Student Essays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad80222-badc-4285-a37a-1ea5e94df7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook, I finetune a sequence classifier model from Hugging Face using the [Hewlett Foundation scored essay data set](https://www.kaggle.com/competitions/asap-aes/data).  \n",
    "This dataset is taken from the training_set_rel3.xlsx on Kaggle. \n",
    "The problem is treated as a regression problem to account for continuous scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c28cb9-3dba-46b5-9829-9a360d45ca53",
   "metadata": {},
   "source": [
    "### 1 - Install and load required dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddf4fe4-3807-4f5c-a2ad-84bbec5d4c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    loralib==0.1.1 --quiet\n",
    "\n",
    "%pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e7bdcc-bb8f-442a-b7f8-49b706dcca8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ef7fb-6d3d-41a1-83d0-ee9d660007fb",
   "metadata": {},
   "source": [
    "## 2 - Define a DataSet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a014c-e20f-441f-b47e-e3b9d017117d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "class EssayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, essays, grades):\n",
    "        self.essays = essays\n",
    "        self.grades = grades\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.essays)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        essay = self.essays[idx]\n",
    "        grade = self.grades[idx]\n",
    "        tokens = self.tokenizer(essay, truncation=True, padding='max_length', max_length=512)\n",
    "        return {key: torch.tensor(val, dtype=torch.long) for key, val in tokens.items()}, torch.tensor(grade, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af0fc5-3926-4b18-a297-1246bb979553",
   "metadata": {},
   "source": [
    "### 3 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c925743-ef2d-4c60-ab82-57bf6dc270e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-38362ed01254b30c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6b8e9c82874c059daaf0508b82cee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'essay', 'domain1_score'],\n",
      "        num_rows: 12978\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files='scored_essays.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bcc14-c9b4-434b-b69c-a38b92871a65",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1 - Shuffle and sample a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76245a47-70ae-45b5-9e93-42cc99b10b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-38362ed01254b30c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c6ce648331b3305d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['essay_id', 'essay', 'domain1_score'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset\n",
    "shuffled_dataset = dataset['train'].shuffle(seed=42)\n",
    "\n",
    "# Select n random samples\n",
    "n_samples = 2000\n",
    "scored_essays = shuffled_dataset.select(range(n_samples))\n",
    "\n",
    "print(scored_essays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4954fc1-f0ef-4ae0-8c42-b744262057f8",
   "metadata": {},
   "source": [
    "#### 3.2 - Extract the essays and grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c71d5e3-613b-4ca3-9dee-df6fb5ac822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essays = scored_essays['essay'] # list of essay strings\n",
    "grades = scored_essays['domain1_score'] # list of numerical grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ee900-dad5-4e1a-b203-3bf3e55e7eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0e7509-be66-41dc-96d2-bd460659c785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and temporary sets (80/20 split)\n",
    "essays_train, essays_temp, grades_train, grades_temp = train_test_split(\n",
    "    essays, grades, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets (50/50 split)\n",
    "essays_val, essays_test, grades_val, grades_test = train_test_split(\n",
    "    essays_temp, grades_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a7d88-7572-4b02-a448-41bca8da9eb1",
   "metadata": {},
   "source": [
    "#### 3.3 Scale the grades  \n",
    "QuantileTransformer: This scaler transforms the features to follow a uniform or a normal distribution.  \n",
    "Therefore, for a given feature, this transformation tends to spread out the most frequent values and reduces the impact of (marginal) outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96452f7c-671e-4acb-9539-7b5773de7a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (200). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (200). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "\n",
    "# Convert grades_train, grades_val, and grades_test lists to numpy arrays\n",
    "grades_train = np.array(grades_train).reshape(-1,1)\n",
    "grades_val = np.array(grades_val).reshape(-1,1)\n",
    "grades_test = np.array(grades_test).reshape(-1,1)\n",
    "\n",
    "# Quantile Transformer\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal')\n",
    "grades_train_scaled = quantile_transformer.fit_transform(grades_train)\n",
    "grades_val_scaled = quantile_transformer.fit_transform(grades_val)\n",
    "grades_test_scaled = quantile_transformer.fit_transform(grades_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a7507-3546-4b9e-9be1-a742ae3ffc28",
   "metadata": {},
   "source": [
    "### 4 - Tokenize the data  \n",
    "Create a dataset where each item is a tuple containing the tokenized essay and the corresponding numerical grade.  \n",
    "These datasets can then be used to create DataLoaders which will handle batching of data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157f9051-5b8f-441e-a2bb-de8a026c540f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = EssayDataset(essays_train, grades_train_scaled)\n",
    "val_dataset = EssayDataset(essays_val, grades_val_scaled)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ad8cc-dafe-4a69-8c5b-b6ed35873f69",
   "metadata": {},
   "source": [
    "#### 4.1 - Initialize the original model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe49bd43-c526-4c49-84ae-ae9ee5c48688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "original_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1)  # For regression\n",
    "optimizer = AdamW(original_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1fe95-3fa1-42e3-b850-d7fe89a3dfbe",
   "metadata": {},
   "source": [
    "#### 4.2 - Print the number of trainable model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918a4389-6dd9-4a39-81fd-fbef1484a175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 109483009\n",
      "all model parameters: 109483009\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb580252-1972-481c-8e97-de20b8704ace",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5 - Full fine tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc4d1f-0cf2-4fa4-bccc-30aecb6c8051",
   "metadata": {},
   "source": [
    "Train for one epoch initially to be sure the training and validation steps work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d703f-fc14-4039-a651-450c0e6f07be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 1  # Number of training epochs\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    original_model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Unpack the tokenized tensors and grades from the batch\n",
    "        tokenized_tensors = batch[0]\n",
    "        grade = batch[1]\n",
    "        \n",
    "        # Extract the tokenized tensors\n",
    "        input_ids = tokenized_tensors['input_ids']\n",
    "        attention_mask = tokenized_tensors['attention_mask']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = original_model(input_ids=input_ids, attention_mask=attention_mask, labels=grade)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Training loss: {train_loss / len(train_dataloader)}')\n",
    "    \n",
    "\n",
    "   # Validation\n",
    "    original_model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            # Directly unpack the batch\n",
    "            tokenized_tensors = batch[0]\n",
    "            grades = batch[1]\n",
    "        \n",
    "            input_ids = tokenized_tensors['input_ids']\n",
    "            attention_mask = tokenized_tensors['attention_mask']\n",
    "            labels = grade\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = original_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            val_preds.extend(outputs.logits.squeeze().tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    val_mse = mean_squared_error(val_labels, val_preds)\n",
    "    print(f'Validation MSE: {val_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92417349-0e19-478b-8a60-025925603faf",
   "metadata": {},
   "source": [
    "Modify code to include early stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd390eb-a24f-4923-b0a2-8821b6641455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "n_epochs = 20  # Make this a high number to benefit from early stopping\n",
    "patience = 5  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0  # Counter for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    original_model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Unpack the tokenized tensors and grades from the batch\n",
    "        tokenized_tensors = batch[0]\n",
    "        grade = batch[1]\n",
    "        \n",
    "        # Extract the tokenized tensors\n",
    "        input_ids = tokenized_tensors['input_ids']\n",
    "        attention_mask = tokenized_tensors['attention_mask']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = original_model(input_ids=input_ids, attention_mask=attention_mask, labels=grade)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Training loss: {train_loss / len(train_dataloader)}')\n",
    "    \n",
    "\n",
    "   # Validation\n",
    "    original_model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            # Directly unpack the batch\n",
    "            tokenized_tensors = batch[0]\n",
    "            grade = batch[1]\n",
    "        \n",
    "            input_ids = tokenized_tensors['input_ids']\n",
    "            attention_mask = tokenized_tensors['attention_mask']\n",
    "            labels = grade\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = original_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            val_preds.extend(outputs.logits.squeeze().tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    val_mse = mean_squared_error(val_labels, val_preds)\n",
    "    print(f'Validation MSE: {val_mse}')\n",
    "    \n",
    "    # Check if validation loss improved\n",
    "    if val_mse < best_val_loss:\n",
    "        best_val_loss = val_mse\n",
    "        best_model = copy.deepcopy(original_model.state_dict())\n",
    "        patience_counter = 0\n",
    "        print(f'Validation MSE improved to {val_mse}. Saving model!')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation MSE did not improve. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Stopping early after {patience_counter} epochs without improvement.')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec38dd-9631-4f9c-86af-e39fbf892da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the best model and the corresponding tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435ddb3-0b54-45ca-b86e-1ae0dc1c4381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = './full-finetune-essay-score-training'\n",
    "\n",
    "# Ensure the best model weights are loaded\n",
    "original_model.load_state_dict(best_model)\n",
    "\n",
    "# Save model weights\n",
    "original_model.save_pretrained(model_path)\n",
    "\n",
    "# Save tokenizer from the train_dataset\n",
    "train_dataset.tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f1af2-4720-495b-8cd2-8e8f08525cea",
   "metadata": {},
   "source": [
    "Optional: Reload model and tokenizer from file when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf013fe-7f98-4f00-88e8-8b76d7a25b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60039e-d3b4-47d7-a00f-1d04bd99f83c",
   "metadata": {},
   "source": [
    "### 6 - Parameter efficient fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c9833-b1e9-414c-bf2a-e3d05f181d5d",
   "metadata": {},
   "source": [
    "#### 6.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
    "\n",
    "Performing full-finetuning can lead to catastrophic forgetting because it changes all parameters on the model. Since PEFT only updates a small subset of parameters, it's more robust against this catastrophic forgetting effect.\n",
    "\n",
    "Set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b388af-0a15-47ee-97ff-e4f688d3034b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft==0.3.0 --quiet\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,  # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.self.query\", \"attention.self.value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS # Sequence classificatio task\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c927b-7aee-4cb9-b1b9-4b7a1d99cb16",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.2 - Add LoRA adapter layers/parameters to the original LLM to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9bbd6f-e4f5-436c-b8da-b58c65983e58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 1181186\n",
      "all model parameters: 110663426\n",
      "percentage of trainable model parameters: 1.07%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model, lora_config)\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e1d4c-b2b6-485e-a7bb-1fe7926ba97c",
   "metadata": {},
   "source": [
    "#### 6.3 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740f47e2-38b7-44b0-83f2-47a169290b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss: 0.9469961788132787\n",
      "Validation MSE: 0.7365528004692424\n",
      "Validation MSE improved to 0.7365528004692424. Saving model!\n",
      "Epoch 2, Training loss: 0.6022367420792579\n",
      "Validation MSE: 0.6282056848808154\n",
      "Validation MSE improved to 0.6282056848808154. Saving model!\n",
      "Epoch 3, Training loss: 0.4471785858646035\n",
      "Validation MSE: 0.654266343730865\n",
      "Validation MSE did not improve. Patience: 1/5\n",
      "Epoch 4, Training loss: 0.4250129825156182\n",
      "Validation MSE: 0.7791248460339716\n",
      "Validation MSE did not improve. Patience: 2/5\n",
      "Epoch 5, Training loss: 0.5221770444791765\n",
      "Validation MSE: 0.7224576622965544\n",
      "Validation MSE did not improve. Patience: 3/5\n",
      "Epoch 6, Training loss: 0.3821337918192148\n",
      "Validation MSE: 0.7441996288568903\n",
      "Validation MSE did not improve. Patience: 4/5\n",
      "Epoch 7, Training loss: 0.34620294894091785\n",
      "Validation MSE: 0.7106972401324078\n",
      "Validation MSE did not improve. Patience: 5/5\n",
      "Stopping early after 5 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "n_epochs = 20  # Make this a high number to benefit from early stopping\n",
    "patience = 5  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0  # Counter for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr=1e-3) # Higher learning rate than full fine tuning\n",
    "\n",
    "peft_model_path = './peft-finetune-essay-score-training'\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    peft_model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Unpack the tokenized tensors and grades from the batch\n",
    "        tokenized_tensors = batch[0]\n",
    "        grade = batch[1]\n",
    "        \n",
    "        # Extract the tokenized tensors\n",
    "        input_ids = tokenized_tensors['input_ids']\n",
    "        attention_mask = tokenized_tensors['attention_mask']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=grade)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Training loss: {train_loss / len(train_dataloader)}')\n",
    "    \n",
    "\n",
    "   # Validation\n",
    "    peft_model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            # Directly unpack the batch\n",
    "            tokenized_tensors = batch[0]\n",
    "            grade = batch[1]\n",
    "        \n",
    "            input_ids = tokenized_tensors['input_ids']\n",
    "            attention_mask = tokenized_tensors['attention_mask']\n",
    "            labels = grade\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = peft_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            val_preds.extend(outputs.logits.squeeze().tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    val_mse = mean_squared_error(val_labels, val_preds)\n",
    "    print(f'Validation MSE: {val_mse}')\n",
    "    \n",
    "    # Check if validation loss improved\n",
    "    if val_mse < best_val_loss:\n",
    "        best_val_loss = val_mse\n",
    "        best_model = copy.deepcopy(peft_model.state_dict())\n",
    "        patience_counter = 0\n",
    "        print(f'Validation MSE improved to {val_mse}. Saving model!')\n",
    "        \n",
    "        # Save best model to disk\n",
    "        # First ensure the best model weights are loaded\n",
    "        peft_model.load_state_dict(best_model)\n",
    "\n",
    "        # Save model weights\n",
    "        peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "        # Save tokenizer from the train_dataset\n",
    "        train_dataset.tokenizer.save_pretrained(peft_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation MSE did not improve. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Stopping early after {patience_counter} epochs without improvement.')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda7e6a-ffa9-439b-a18d-a66191d0a4b6",
   "metadata": {},
   "source": [
    "#### 6.4 - Save the final best model and the corresponding tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0702c218-10ba-431f-8729-48d22f821811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-finetune-essay-score-training/tokenizer_config.json',\n",
       " './peft-finetune-essay-score-training/special_tokens_map.json',\n",
       " './peft-finetune-essay-score-training/vocab.txt',\n",
       " './peft-finetune-essay-score-training/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path = './peft-finetune-essay-score-training'\n",
    "\n",
    "# Ensure the best model weights are loaded\n",
    "peft_model.load_state_dict(best_model)\n",
    "\n",
    "# Save model weights\n",
    "peft_model.save_pretrained(peft_model_path)\n",
    "\n",
    "# Save tokenizer from the train_dataset\n",
    "train_dataset.tokenizer.save_pretrained(peft_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1185701-56e8-4bec-bac4-af00df418518",
   "metadata": {},
   "source": [
    "#### 6.5 - Prepare this model by adding an adapter to the original model.   \n",
    "Set is_trainable=False because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set is_trainable=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e9e73d0-a705-43de-be8e-9ecb1c17b212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = BertForSequenceClassification.from_pretrained(model_name, num_labels=1, torch_dtype=torch.bfloat16)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       peft_model_path, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       num_labels=1,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9adf82-b734-45de-b738-fc29a43ffb1d",
   "metadata": {},
   "source": [
    "### 7 - Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10883037-14df-4fd7-9b18-e1a1e1d4028f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.1 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "Make inferences with the original model and PEFT model for one test instance initially.  \n",
    "Please note the original model would normally be the fully fine tuned model.  \n",
    "I have not fine tuned the original model fully to conserve resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97c4b6ca-b270-4d7d-ac60-7f7b24b1a0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE HUMAN SCORE: 1.0\n",
      "ORIGINAL MODEL SCORE: 1.0\n",
      "PEFT MODEL SCORE: 1.0\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "\n",
    "essay = essays_test[index]\n",
    "scaled_score = grades_test_scaled[index]\n",
    "\n",
    "# Prepare the prompt and tokenize\n",
    "prompt = f\"Assign a score to the following essay:\\n\\n{essay}\\n\\nScore:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Move tensors to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Make sure your models are in evaluation mode\n",
    "original_model.eval()\n",
    "peft_model.eval()\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    # Get model predictions\n",
    "    original_model_outputs = original_model(**inputs)\n",
    "    peft_model_outputs = peft_model(**inputs)\n",
    "\n",
    "    # Extract the score from the outputs (assuming a single regression output)\n",
    "    original_model_score = original_model_outputs.logits.squeeze().item()\n",
    "    peft_model_score = peft_model_outputs.logits.squeeze().item()\n",
    "    \n",
    "    # Scale the grades back to their original values\n",
    "    original_model_score = quantile_transformer.inverse_transform(np.array(original_model_score).reshape(-1,1))\n",
    "    y_pred_original = quantile_transformer.inverse_transform(np.array(peft_model_score).reshape(-1,1))\n",
    "    y_test_original = quantile_transformer.inverse_transform(np.array(scaled_score).reshape(-1,1))\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"BASELINE HUMAN SCORE: {y_test_original[0][0]:.1f}\")\n",
    "print(f\"ORIGINAL MODEL SCORE: {original_model_score[0][0]:.1f}\") #This would normally be the score from the fully fine tined model\n",
    "print(f\"PEFT MODEL SCORE: {y_pred_original[0][0]:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1993a-7744-414e-ade5-a09af520df3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.2 - Evaluate the performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26729f-cc74-41f8-9a17-9dbb3f4e7813",
   "metadata": {},
   "source": [
    "For regression tasks, the concept of an error percentage is not as straightforward as in classification tasks because the range of possible values is not bounded between 0 and 1. However, there are relative error metrics that can provide a sense of the error relative to the magnitude of the values being predicted. One such metric is the Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "MAPE measures the size of the error in percentage terms. It is calculated as the average of the absolute percentage errors of the predictions.  \n",
    "\n",
    "MAPE has some drawbacks, though:\n",
    "\n",
    "It can be undefined if any y true values are or close to zero.  \n",
    "It puts a heavier penalty on negative errors than positive ones in certain contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ad97bd-7cda-44ac-aae5-a461ce314e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping essay 5 with length 766...\n",
      "Processing batch 10/200\n",
      "Skipping essay 11 with length 834...\n",
      "Skipping essay 20 with length 720...\n",
      "Processing batch 30/200\n",
      "Skipping essay 37 with length 624...\n",
      "Processing batch 40/200\n",
      "Skipping essay 42 with length 861...\n",
      "Skipping essay 45 with length 576...\n",
      "Skipping essay 49 with length 595...\n",
      "Processing batch 50/200\n",
      "Skipping essay 55 with length 570...\n",
      "Skipping essay 57 with length 626...\n",
      "Processing batch 60/200\n",
      "Skipping essay 66 with length 776...\n",
      "Processing batch 70/200\n",
      "Skipping essay 71 with length 669...\n",
      "Skipping essay 75 with length 539...\n",
      "Skipping essay 76 with length 627...\n",
      "Skipping essay 79 with length 611...\n",
      "Processing batch 80/200\n",
      "Skipping essay 83 with length 695...\n",
      "Skipping essay 87 with length 996...\n",
      "Skipping essay 89 with length 747...\n",
      "Processing batch 90/200\n",
      "Skipping essay 93 with length 525...\n",
      "Skipping essay 98 with length 777...\n",
      "Processing batch 100/200\n",
      "Skipping essay 105 with length 588...\n",
      "Skipping essay 109 with length 840...\n",
      "Processing batch 110/200\n",
      "Skipping essay 117 with length 810...\n",
      "Processing batch 120/200\n",
      "Skipping essay 121 with length 568...\n",
      "Skipping essay 125 with length 531...\n",
      "Skipping essay 126 with length 515...\n",
      "Processing batch 130/200\n",
      "Skipping essay 131 with length 637...\n",
      "Processing batch 140/200\n",
      "Skipping essay 141 with length 927...\n",
      "Skipping essay 145 with length 940...\n",
      "Skipping essay 150 with length 544...\n",
      "Skipping essay 151 with length 1098...\n",
      "Skipping essay 154 with length 689...\n",
      "Skipping essay 156 with length 670...\n",
      "Processing batch 160/200\n",
      "Skipping essay 165 with length 762...\n",
      "Processing batch 170/200\n",
      "Skipping essay 175 with length 740...\n",
      "Skipping essay 176 with length 1068...\n",
      "Processing batch 180/200\n",
      "Processing batch 190/200\n",
      "\n",
      "\n",
      "Mean Squared Error: 5.79\n",
      "Mean Absolute Error: 1.16\n",
      "Mean Absolute Percentage Error (MAPE): inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2984/2160044727.py:6: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "n=10 # print progress every nth batch\n",
    "y_test = []\n",
    "y_pred = []\n",
    "max_length = 512  # Maximum length for BERT-based models\n",
    "\n",
    "for index in range(len(essays_test)):\n",
    "#for index in range(30,35): # skip long essays that are longer than the token limit\n",
    "    \n",
    "    essay = essays_test[index]\n",
    "    scaled_score = grades_test_scaled[index]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Assign a score to the following essay.\n",
    "    \n",
    "    {essay}\n",
    "    \n",
    "    Score:\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Check the length of the tokenized essay\n",
    "    input_length = inputs.input_ids.size(1)\n",
    "    if input_length > max_length:\n",
    "        print(f\"Skipping essay {index} with length {input_length}...\")\n",
    "        continue\n",
    "    \n",
    "    # Move tensors to the same device as the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make sure your models are in evaluation mode\n",
    "    original_model.eval()\n",
    "    peft_model.eval()\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions\n",
    "        peft_model_outputs = peft_model(**inputs)\n",
    "        peft_model_score = peft_model_outputs.logits.squeeze().item()\n",
    "\n",
    "        y_pred.append(peft_model_score)\n",
    "        y_test.append(scaled_score)\n",
    "    \n",
    "    # Print progress message every nth iteration\n",
    "    if index % n == 0:\n",
    "        print(f\"Processing batch {index}/{len(essays_test)}\")    \n",
    "        \n",
    "# Scale the grades back to their original values\n",
    "y_pred_original = quantile_transformer.inverse_transform(np.array(y_pred).reshape(-1,1))\n",
    "y_test_original = quantile_transformer.inverse_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "# Calculate MSE, MAE, MAPE\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427a254-4b85-4181-9444-309dbfc0d68a",
   "metadata": {},
   "source": [
    "#### 7.3 Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f730d1-9b16-4dba-a8d4-4945a327ca95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test_original, y_pred_original)\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.plot([min(y_test_original), max(y_test_original)], [min(y_test_original), max(y_test_original)], color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e438e-2420-49eb-b276-7549cb8eca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
