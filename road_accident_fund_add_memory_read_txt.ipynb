{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa8f357-7268-4958-9540-e4126c012d37",
   "metadata": {},
   "source": [
    "### Extracting Legal Information  \n",
    "This notebook extracts information from legal documentation pertaining to a dispute between the Road Accident Fund and other parties. As the source files are scanned pdfs, the input files to this notebook are the OCR processed files. OCR was done separately. All legal documents used here are in the public domain.  \n",
    "This notebook uses:  \n",
    "- Langchain to load, retrieve information and generate responses.  \n",
    "- OpenAI Embeddings  \n",
    "- FAISS in-memory vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584eb08c-927d-40a0-a5a4-3c73e0a3ba54",
   "metadata": {},
   "source": [
    "##### Load the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca84868-e7b0-4547-b42a-8711b4494444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unstructured\n",
    "#!pip install tqdm # This useful for showing progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3625826-0e6f-4e0c-950b-66881a142a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa658af-c7f9-4fbc-bcb4-11c5cf208dcd",
   "metadata": {},
   "source": [
    "#### 1 - Import dependencies and set up the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "599b6877-cadc-40ce-8e8e-cd467a991e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d66703-3db2-4d33-9f01-d7d0d1958a64",
   "metadata": {},
   "source": [
    "##### Read in the OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c91dd6-2fb1-42f3-bdca-e08ff74f9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Read OpenAI API key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API Key not set in environment variables\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123137f-a7e7-496b-a715-7272766ecfa2",
   "metadata": {},
   "source": [
    "##### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4381bfda-bef9-4ecb-bacf-c5c4c3033901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    #model = \"gpt-4-1106-preview\", # Note: Map reduce with GPT4 is long and costly\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7997a8-1af1-44e7-9221-058bd3dfbf3f",
   "metadata": {},
   "source": [
    "#### 2 - Read in the questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d60f406c-43f9-48fe-b99d-b148af9c8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions commented out were rephrased to elicit better responses.\n",
    "\n",
    "question_1 = \"What is the central legal claim or cause of action asserted in the pleadings?\"\n",
    "question_2 = \"Can you provide a concise summary of the background facts leading to the legal dispute?\"\n",
    "question_3 = \"What specific legal theories or statutes form the basis of the claims made?\"\n",
    "#question_4 = \"Are there any precedents or case law cited that support these legal arguments?\"\n",
    "question_4 = \"Are there any precedents or case law cited that support these legal arguments? Think step by step before answering and list each one.\"\n",
    "#question_5 = \"Who are the plaintiffs and defendants named in the pleadings?\"\n",
    "question_5 = \"Who are the plaintiffs and defendants named in the pleadings? Give the name of each one.\"\n",
    "#question_6 = \"Are there any third parties mentioned, and what roles do they play in the case?\"\n",
    "question_6 = \"Are there any third parties mentioned, and what roles do they play in the case? Give the name and role of each one.\"\n",
    "question_7 = \"What are the key factual allegations made by each party?\"\n",
    "question_8 = \"Are there specific incidents or events that are crucial to the case?\"\n",
    "question_9 = \"What remedies or relief are the parties seeking from the court?\"\n",
    "question_10 = \"Are there any specific damages claimed, and how are they quantified?\"\n",
    "question_11 = \"Does the pleading establish the court's jurisdiction over the matter?\"\n",
    "question_12 = \"Is the chosen venue appropriate, and are there any challenges to jurisdiction?\"\n",
    "#question_13 = \"What defenses are asserted by the opposing party?\"\n",
    "question_13 = \"Can you list and explain the defenses that the opposing parties have asserted in these legal documents?\"\n",
    "#question_14 = \"Are there affirmative defenses or counterclaims presented?\"\n",
    "question_14 = \"Are there affirmative defenses or counterclaims presented? Think step by step before answering and list each one.\"\n",
    "question_15 = \"Are the pleadings clear and logically organized?\"\n",
    "question_16 = \"Are there any inconsistencies or contradictions within the pleadings?\"\n",
    "question_17 = \"Are there any documents referenced or attached to the pleadings?\"\n",
    "question_18 = \"How do these documents support or undermine the parties' claims?\"\n",
    "question_19 = \"Are there identified witnesses whose testimony is crucial to the case?\"\n",
    "question_20 = \"How do the pleadings anticipate presenting evidence during the proceedings?\"\n",
    "#question_21 = \"Have the pleadings addressed any applicable timelines or statutes of limitations?\"\n",
    "question_21 = \"Please list all applicable timelines or statutes of limitations mentioned in the pleadings.\"\n",
    "question_22 = \"Are there any time-sensitive elements that may impact the case?\"\n",
    "question_23 = \"Have there been any attempts at settlement or ADR mentioned in the pleadings?\"\n",
    "\n",
    "# Here are the second round questions\n",
    "\n",
    "#question_24 = \"In terms of the case which has been filed under case number 2023-134420, what time was the annexe documentation filed by the registrar of the court?\"\n",
    "question_24 = \"A case was filed under case number 2023-134420. Tell me the exact date the document was filed \\\n",
    "by the registrar of the court. Also tell me the exact time of day the document was filed by the registrar of the court.\"\n",
    "question_25 = \"In terms of the notice of motion marked annexe “A1”, please summarise the orders that the road accident fund is \\\n",
    "seeking from the court.\"\n",
    "question_26 = \"Please summarise the order contained in paragraph 11.1 of the rule 16A notice document which is titled annexe 'A2'.\"\n",
    "#question_26a = \"Please summarise the order contained in paragraph 11.1 of notice of motion long form document.\"\n",
    "question_27 = \"According to the documents provided, how many people are injured annually in South Africa as a consequence of \\\n",
    "motor vehicle accidents?\"\n",
    "#question_28 = \"What does the anacronym RNYP stand for?\"\n",
    "question_28 = \"What is the purpose of the RNYP list?\"\n",
    "question_29 = \"What is the physical address of Malatji and Co. Attorneys?\"\n",
    "question_30 = \"In terms of the court papers provided, the relief that the applicant will seek will have an impact on the \\\n",
    "person’s rights in terms of the Bill of Rights of the Constitution of South Africa, 1996. What specific impacts are listed?\"\n",
    "#question_31 = \"Please provide the full case citation of the case involving the Matjhabeng Local Municipality.\"\n",
    "question_31 = \"What does the document say about Matjhabeng?\"\n",
    "question_32 = \"What must a court be cautious not to usurp?\"\n",
    "question_33 = \"Please provide the names of the Advocate who appeared for the 15th respondent in the matter with \\\n",
    "case number reference 58145/2020.\"\n",
    "question_34 = \"What is the RAF claim number, in respect of Sithole, R?\"\n",
    "question_35 = \"In terms of the document entitled Annexe “A.10.1”, within which period must solar panels be purchased and \\\n",
    "installed at a private residence, in order for a taxpayer to qualify for the tax rebate?\"\n",
    "question_36 = \"In terms of the document entitled Annexe “A.10.1”, what will the minimum royalty rate be increased to?\"\n",
    "question_37 = \"In terms of the document entitled Annexe “A.10.2”, please list SARS’ 9 stated strategic objectives.\" \n",
    "question_38 = \"In terms of the document entitled Annexe “A.10.3”, please list SARS’ 9 stated strategic objectives.\" \n",
    "question_38 = \"What are the main tax proposals for fiscal 2023/24?\"\n",
    "\n",
    "\n",
    "# Create a list of questions\n",
    "questions = [eval(f'question_{i}') for i in range(1, 39)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd57315-e094-4d67-912b-ea95058d3581",
   "metadata": {},
   "source": [
    "#### 3 - Create Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8046c-5a83-451d-a96a-8518bf96749b",
   "metadata": {},
   "source": [
    "##### Create a function to build the vector data base from the source OCR processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6647b83a-fea8-496e-b195-34b347b1e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(source_directory):\n",
    "    loader = DirectoryLoader(source_directory, glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "    pages=loader.load()\n",
    "\n",
    "    # Define chunk size, overlap and separators\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=7000, #experiment with this\n",
    "        chunk_overlap=700,\n",
    "        separators=['\\n\\n', '\\n', '(?=>\\. )', ' ', '']\n",
    "    )\n",
    "    docs  = text_splitter.split_documents(pages)\n",
    "\n",
    "    # Select the embeddings to use\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    #Create the vectorized db\n",
    "    # Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "\n",
    "    vector_db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    return vector_db, docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251c036-140d-458d-86e5-471f9a8ddb9f",
   "metadata": {},
   "source": [
    "##### Create a function to summarize the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6525a0-bfa1-4729-9d4d-7fef3bde00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_doc(docs):\n",
    "\n",
    "    summarization_prompt = \"\"\"\n",
    "    Write a concise summary of the following:\n",
    "    {text}\n",
    "    CONCISE SUMMARY:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=summarization_prompt, input_variables=[\"text\"])\n",
    "\n",
    "    summary_chain = load_summarize_chain(\n",
    "    llm = model,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=prompt,\n",
    "    combine_prompt=prompt\n",
    "    )\n",
    "\n",
    "    summary = summary_chain.run(docs)\n",
    "    #print(summary)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7f9a4-e260-49d4-b036-2dcd58442bb9",
   "metadata": {},
   "source": [
    "##### Create a function to create the retrieval chain with conversation history and memory\n",
    "First add in Conversational History  \n",
    "Given a conversation history and a follow-up question, the goal is to rephrase the follow-up question so that it becomes a standalone question.  \n",
    "This means the rephrased question should be understandable without needing the context of the chat history.  \n",
    "\n",
    "Then format and combine multiple documents into a single string. Each document is formatted according to a specified or default template, and then they are combined into one string, with each document separated by a specified separator.  \n",
    "\n",
    "Finally, add in memory and return source documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ca63e-72cb-4367-b26e-3355234e983e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01170c2a-06a8-4aee-bcdb-b7cdc89aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieval_chain():\n",
    "    # Given the chat history, rephrase the follow-up question to be a stand-alone question.\n",
    "    _template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question \\\n",
    "    to be a standalone question, in its original language.\n",
    "    \n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "    Follow Up Input: {question}\n",
    "    Standalone question:\"\"\"\n",
    "    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "    # Create a summary prompt template from the document summary\n",
    "    summary_template = PromptTemplate(input_variables=[\"summary\"], template=\"{summary}\")\n",
    "\n",
    "    # Add it to the QA prompt template\n",
    "    template = summary_template.format(summary=summary) + \"\"\"\n",
    "    You are an AI trained as an experienced legal assistant, well-versed in South African contract law. \n",
    "    Your responses should be careful, concise, and legally authoritative, drawing specifically from the provided context. \n",
    "    If the answer to a question is not clearly supported by the context, state that you do not know the answer. \n",
    "    Avoid speculations or assumptions outside the given context. \n",
    "    Focus on delivering brief, factual, and directly relevant responses.\n",
    "\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Format and combine multiple documents into a single string\n",
    "    DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "    def _combine_documents(\n",
    "        docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "    ):\n",
    "        doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "        return document_separator.join(doc_strings)\n",
    "\n",
    "    # First we add a step to load memory\n",
    "    # This adds a \"memory\" key to the input object\n",
    "    loaded_memory = RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    "    )\n",
    "    # Now we calculate the standalone question\n",
    "    standalone_question = {\n",
    "        \"standalone_question\": {\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "        }\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | model\n",
    "        | StrOutputParser(),\n",
    "    }\n",
    "    # Now we retrieve the documents\n",
    "    retrieved_documents = {\n",
    "        \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "        \"question\": lambda x: x[\"standalone_question\"],\n",
    "    }\n",
    "    # Now we construct the inputs for the final prompt\n",
    "    final_inputs = {\n",
    "        \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    # And finally, we do the part that returns the answers\n",
    "    answer = {\n",
    "        \"answer\": final_inputs | ANSWER_PROMPT | model,\n",
    "        \"docs\": itemgetter(\"docs\"),\n",
    "    }\n",
    "    # And now we put it all together!\n",
    "    final_chain = loaded_memory | standalone_question | retrieved_documents | answer\n",
    "\n",
    "    return final_chain, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72625c5b-98a7-4609-b9b1-75821ae60032",
   "metadata": {},
   "source": [
    "#### 4 - Run the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2c955-bf1f-4209-926c-fad5419e6983",
   "metadata": {},
   "source": [
    "##### A - Create the vector data base from the source OCR processed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a859811-5da5-428b-8fb1-34e1653a03f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████▎              | 4/6 [00:00<00:00, 487.03it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_db, docs = create_vector_db(source_directory=\"./RAF_ocr_docs/\") \n",
    "#This is a one time event and can take some time depending on the length of the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea68d2-a8da-4944-964e-7104e974b650",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### B - Create a summary of the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6f727-c51a-48e8-ae1e-64e3af88bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "# Format the date and time as a string\n",
    "formatted_time = current_time.strftime(\"Started summarizing document at %Y-%m-%d %H:%M:%S\")\n",
    "# Print the formatted date and time\n",
    "print(formatted_time)\n",
    "\n",
    "summary = summarize_doc(docs) #This is a one time event and can take some time\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "# Format the date and time as a string\n",
    "formatted_time = current_time.strftime(\"Finished summarizing document at %Y-%m-%d %H:%M:%S\")\n",
    "# Print the formatted date and time\n",
    "print(formatted_time + \"\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f76b3-9cfb-4a76-a192-eea40bf527ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit as necesary\n",
    "summary = \"\"\"\n",
    "The document addresses financial challenges faced by the Road Accident Fund and its request for court relief to fulfill its \\\n",
    "obligations to claimants. The RAF seeks court intervention to prevent financial collapse and manage its obligations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b547fc-7078-4c49-b22e-4096c533de4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### C - Optional: Save summary to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200490f9-fb3d-410b-8d4f-92f7b7bca7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename where you want to save the summary\n",
    "filename = \"./RAF_summaries//summary.txt\"\n",
    "\n",
    "# Open the file in write mode and write the summary\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(summary)\n",
    "\n",
    "print(f\"The document summary has been saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab3d12-2251-474f-8f86-9acc4c69d09e",
   "metadata": {},
   "source": [
    "##### D - Optional: Load summary from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "462aa757-82c1-486f-a061-6b11c94ea7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " \n",
      "The document addresses financial challenges faced by the Road Accident Fund and its request for court relief to fulfill its obligations to claimants. The RAF seeks court intervention to prevent financial collapse and manage its obligations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename from which you want to load the summary\n",
    "filename = \"./RAF_summaries//summary.txt\"\n",
    "\n",
    "# Open the file in read mode and read the contents\n",
    "with open(filename, 'r') as file:\n",
    "    summary = file.read()\n",
    "\n",
    "# Optionally, print the loaded summary\n",
    "print(f\"Summary:\\n {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e64a5-3d83-4b98-be3f-f902144fa221",
   "metadata": {},
   "source": [
    "#### 5 - Set up the retriever  \n",
    "    \n",
    "Parameters for search_type =  similarity_score_threshold:    \n",
    "search_type=\"similarity_score_threshold\",  \n",
    "search_kwargs={'score_threshold': 0.4},  \n",
    "  \n",
    "Parameters for search_type = Maximal Marginal Relevance (MMR)   \n",
    "k = number of documents to retrieve (default = 4)  \n",
    "lambda_mult = degree of diversity where 0 is more (default = 0.5)  \n",
    "fetch_k = number of documents to return to the mmr algorithm (default = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce888b85-4457-440d-b5cc-c47443f81633",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    #search_kwargs={'k': 6, 'lambda_mult': 0.5, 'fetch_k': 2 },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82c286-890a-4608-9f49-14f94daed6c8",
   "metadata": {},
   "source": [
    "#### 4 - Invoke the retrieval chain and run the questions through the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9166724f-8599-43b0-8ee8-6cfdf65244e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset memory\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205631f8-b3b3-4326-a5d7-b89a4553ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain, memory = create_retrieval_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54aba579-f12b-440d-850d-7d674d672bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWhat is the central legal claim or cause of action asserted in the pleadings?\u001b[0m\n",
      "The central legal claim or cause of action asserted in the pleadings is the request for a suspension of all writs of execution and warrants of attachment against the Road Accident Fund (RAF) based on court orders already granted or settlements already reached in terms of the Road Accident Fund Act, 1996. This request is made to prevent the collapse of the RAF due to its financial instability and inability to make immediate lump sum payments to claimants.\n",
      "\n",
      "\n",
      "\u001b[1mCan you provide a concise summary of the background facts leading to the legal dispute?\u001b[0m\n",
      "The Road Accident Fund (RAF) is experiencing severe financial difficulties, exacerbated by the Covid-19 pandemic, and is at risk of imminent collapse. The RAF seeks extraordinary relief to stabilize its financial position and prevent a constitutional crisis. It seeks a suspension of all writs of execution and attachments against it for a period of 180 days to enable it to prioritize the payment of the oldest claims first. The RAF's financial instability is attributed to the high number of claims against it, the fluctuating payment of the fuel levy, and its dependence on limited financial resources. The RAF's financial situation is further complicated by the fact that it is unable to make lump sum payments for all claims as they fall due, leading to a queue of claimants waiting for payment. The RAF's application is opposed by various parties, including attorneys representing claimants and the Legal Practice Council.\n",
      "\n",
      "\n",
      "\u001b[1mWhat specific legal theories or statutes form the basis of the claims made?\u001b[0m\n",
      "The specific legal theories or statutes forming the basis of the claims made by the Road Accident Fund include:\n",
      "1. Section 3 of the Road Accident Fund Act, 56 of 1996, which outlines the object of the RAF as the payment of compensation for loss or damage wrongfully caused by the driving of a motor vehicle.\n",
      "2. Section 4 of the Road Accident Fund Act, which stipulates the powers of the RAF, including the administration of claims and the management of funds for the purposes connected with its powers and duties.\n",
      "3. Constitutional rights under the Bill of Rights of the Constitution of South Africa, 1996, including the right to equality, dignity, life, freedom and security of persons, healthcare, food, water, and social security.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    inputs = {\"question\": question}\n",
    "    result = final_chain.invoke(inputs)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\033[1m\" + question + \"\\033[0m\")\n",
    "    print(result['answer'].content)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Save the memory manually\n",
    "    memory.save_context(inputs, {\"answer\": result[\"answer\"].content})\n",
    "\n",
    "    # Load the memory\n",
    "    memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0645a88-21a9-4eab-a7f3-64b5a358b348",
   "metadata": {},
   "source": [
    "Here is how you can see the chat history used to answer the last question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "591355b7-fb67-411a-a1bc-bb23a1f3fd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1e4c2-46fe-4d7f-8bd1-cc0336d254fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dea2-7482-4509-a498-c2863c31c122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e7b744-3251-42b3-bfab-b99df50088f6",
   "metadata": {},
   "source": [
    "#### 5 - Scratchpad for do-over questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "988d57aa-9494-40d4-8f5b-036edb604fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_over_question = \"\"\"\n",
    "who is cto of the raf?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68b1840e-0e2f-4d04-9044-e13a066ad271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "who is cto of the raf?\n",
      "\u001b[0m\n",
      "I do not have that information based on the provided context.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='\\nwhat does the RAF do?\\n'),\n",
       "  AIMessage(content='The role of the Road Accident Fund (RAF) is to pay compensation for loss or damage wrongfully caused by the driving of motor vehicles, in accordance with the RAF Act. Its powers and functions include stipulating the terms and conditions for administering claims and managing the money of the Fund for purposes connected with its duties.'),\n",
       "  HumanMessage(content='\\nwho is the ceo of the raf?\\n'),\n",
       "  AIMessage(content='The CEO of the Road Accident Fund is not explicitly mentioned in the provided context. Therefore, I do not have the information to answer this question.'),\n",
       "  HumanMessage(content='\\nwhen was the raf established?\\n'),\n",
       "  AIMessage(content='The Road Accident Fund (RAF) was established in terms of section 2(1) of the RAF Act. No specific date of establishment is provided in the given context.'),\n",
       "  HumanMessage(content='\\nwho is cto of the raf?\\n'),\n",
       "  AIMessage(content='I do not have that information based on the provided context.')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain, memory = create_retrieval_chain()\n",
    "inputs = {\"question\": do_over_question}\n",
    "result = final_chain.invoke(inputs)\n",
    "\n",
    "# Print results\n",
    "print(\"\\033[1m\" + do_over_question + \"\\033[0m\")\n",
    "print(result['answer'].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Save memory manually\n",
    "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})\n",
    "\n",
    "# Load memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b1f48-5de5-41c4-920e-a61a97917e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750f85fd-2006-41d3-83b0-eb7260b1e81f",
   "metadata": {},
   "source": [
    "##### Alternate ways to summarize the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda4874-0aae-4a8a-b5c7-876b38c4dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "summary_map_reduce=chain.run(docs)\n",
    "print(summary_map_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074862e8-1256-4599-b880-49efaa1c7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "\n",
    "summary_refine=chain.run(docs)\n",
    "print(summary_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf7d0e-fcd7-4802-8fe3-35442eec9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For long documents, this method may exceed the model token limit\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "summary_stuff=chain.run(docs)\n",
    "print(summary_stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e1509-87c1-4536-a1e0-1f9cf7cbf549",
   "metadata": {},
   "source": [
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0d254-0e35-4565-b467-356c725c6014",
   "metadata": {},
   "source": [
    "[Langchain: Retrieval Augmented Generation](https://python.langchain.com/docs/expression_language/cookbook/retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51ceaa-9b8a-4dd9-8286-cf69651ca0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
